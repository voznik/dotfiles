model: ollama:mistral:latest
auto_copy: false
# Visit https://github.com/sigoden/llm-functions for setup instructions
function_calling: true           # Enables or disables function calling (Globally).
mapping_tools:                   # Alias for a tool or toolset
  fs: 'fs_cat,fs_ls,fs_mkdir,fs_rm,fs_write'
use_tools: null                  # Which tools to use by default
save_session: null
##################################################################################
clients:
- type: openai-compatible
  name: ollama
  api_base: http://localhost:11434/v1
  models:
  - name: deepseek-r1:14b
    max_input_tokens: 131072
    supports_function_calling: true
  - name: codestral:latest
    max_input_tokens: 32768
  - name: qwen2.5-coder:14b
    max_input_tokens: 32768
  - name: deepseek-coder-v2:latest
    max_input_tokens: 16384
  - name: mistral-nemo:latest
    max_input_tokens: 16384
  - name: mistral-openorca:latest
    max_input_tokens: 8192
  - name: nomic-embed-text
    type: embedding
    max_tokens_per_chunk: 8192
    default_chunk_size: 1000
    max_batch_size: 50
- type: mistral
  models:
  - name: codestral
    max_input_tokens: 32768
  - name: open-mixtral-8x7b
    max_input_tokens: 32768
  - name: mistral-large-latest
    max_input_tokens: 32768