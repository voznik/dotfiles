[
  {
    "id": "access-currently-stored-preferences",
    "title": "Access Currently Stored Preferences",
    "description": "Retrieve and display the user's currently stored preferences from goose memory",
    "category": "productivity",
    "job": "operations",
    "example_prompt": "What have I asked you to remember?",
    "example_result": "You've asked me to remember the following:\n\n### Personal\n* My name is Ade. I like to read tech blogs, play with technical tools, and i'm interested in building agentic systems.",
    "extensions": [
      {
        "name": "Memory",
        "command": "memory",
        "is_builtin": true,
        "environmentVariables": []
      }
    ]
  },
  {
    "id": "accessibility-audit",
    "title": "Website Accessibility Audit",
    "description": "Conduct a comprehensive accessibility audit of a website, including keyboard navigation, color contrast, and ARIA compliance",
    "category": "technical",
    "job": "design",
    "example_prompt": "Can you check if my website is accessible? Please conduct a full accessibility audit, focusing on the following:\n\n1. Keyboard Navigation: Test all interactive elements (links, buttons, dropdowns, etc.) to ensure they are accessible without a mouse.\n\n2. Color Contrast Analysis: Verify that all text and UI elements meet WCAG contrast ratio standards.\n\n3. Screen Reader Compatibility: Test whether a screen reader can properly interpret content and navigation.\n\n4. ARIA & Semantic HTML Validation: Identify any missing or misused ARIA attributes and ensure proper semantic structure.\n\n5. Error Identification & Screenshots: Provide a comprehensive report with identified issues, along with screenshots if necessary.\n\n6. Fixes & Code Recommendations: Suggest HTML, CSS, or JavaScript changes to resolve any compliance issues.\n\nHere is the website to test: [URL]. I want to ensure that our documentation meets accessibility standards. Please generate a detailed report with steps to fix any issues found.",
    "example_result": "I've completed the accessibility audit of your website. Here are the findings:\n\n1. Keyboard Navigation:\n- All interactive elements are keyboard accessible\n- Focus indicators are visible\n- Tab order is logical\n\n2. Color Contrast:\n- Main text meets WCAG AA standards (ratio 4.5:1)\n- Warning: Header text #FF8C00 on white background fails contrast requirements\n\n3. Screen Reader Compatibility:\n- All images have appropriate alt text\n- Headings are properly structured (H1 ‚Üí H2 ‚Üí H3)\n- Form fields have associated labels\n\n4. ARIA & Semantic HTML:\n- Navigation uses <nav> element correctly\n- Missing aria-label on search form\n- Article sections use appropriate semantic tags\n\nRecommended Fixes:\n\n```html\n<!-- Update header text color for better contrast -->\n<h1 style=\"color: #D35400;\">Welcome</h1>\n\n<!-- Add aria-label to search form -->\n<form aria-label=\"Search website\">\n  <input type=\"search\" name=\"q\">\n</form>\n```\n\nPriority fixes:\n1. Adjust header text color to meet contrast requirements\n2. Add missing ARIA labels to interactive elements\n3. Implement skip navigation for keyboard users",
    "extensions": [
      {
        "name": "Puppeteer",
        "command": "npx -y @modelcontextprotocol/server-puppeteer",
        "is_builtin": false,
        "environmentVariables": []
      },
      {
        "name": "Developer",
        "command": "developer",
        "is_builtin": true,
        "environmentVariables": []
      }
    ]
  },
  {
    "id": "ai-content-detection",
    "title": "AI Content Detection Policies",
    "description": "Enforce content policies by detecting AI-generated submissions and ensuring compliance with platform guidelines",
    "category": "business",
    "job": "marketing-content",
    "example_prompt": "Please analyze the provided content for:\n1. Indicators of AI generation\n2. Policy compliance issues\n3. Required disclosures or missing attributions\n\nProvide a detailed report including:\n- AI detection confidence score\n- Policy violation alerts\n- Recommended actions\n- Suggested improvements for compliance",
    "example_result": "Content Analysis Report\n\nSubmitted Text: \"The Future of Quantum Computing\"\n\nAI Detection Results:\n- Confidence Score: 87% likely AI-generated\n- Key Indicators:\n  - Consistent writing style throughout\n  - Advanced technical terminology used uniformly\n  - Repetitive phrase patterns detected\n  - Limited personal perspective or anecdotes\n\nPolicy Compliance Review:\n1. Attribution Issues:\n  - Missing citations for technical claims\n  - No references to original research\n  - Required attribution disclaimer absent\n\n2. Content Guidelines:\n  - Technical accuracy: Passed\n  - Originality check: Failed (similar content found)\n  - Disclosure requirements: Not met\n\nRequired Actions:\n1. Add AI-generated content disclaimer\n2. Include citations for technical claims\n3. Differentiate from existing published content\n4. Add human editorial oversight statement\n\nRecommended Improvements:\n```markdown\n# Original Content\nThe Future of Quantum Computing...\n\n# Improved Version\n[AI-Generated Content Disclaimer]\nThe Future of Quantum Computing\nEdited by: [Editor Name]\n\nAs explored in [Citation 1], quantum computing...\n\nAccording to research by [Institution]...\n\n# Footer\nThis content was generated with AI assistance and reviewed by our editorial team. Citations and references available upon request.\n```\n\nCompliance Score: 65/100\nStatus: Requires Revision",
    "extensions": [
      {
        "name": "Computer Controller",
        "command": "computercontroller",
        "is_builtin": true,
        "environmentVariables": []
      },
      {
        "name": "Google Drive",
        "command": "npx -y @modelcontextprotocol/server-gdrive",
        "is_builtin": false,
        "environmentVariables": [
          {
            "name": "GDRIVE_OAUTH_PATH",
            "description": "/Users/<username>/.config/gcp-oauth.keys.json / ",
            "required": true
          },
          {
            "name": "GDRIVE_CREDENTIALS_PATH",
            "description": "/Users/<username>/.config/.gdrive-server-credentials.json /",
            "required": true
          }
        ]
      }
    ]
  },
  {
    "id": "ai-culinary-innovation-studio",
    "title": "AI Culinary Innovation Studio",
    "description": "Revolutionary kitchen laboratory that creates novel recipes by fusing global cuisines, analyzes nutritional profiles, generates professional cooking techniques, and designs stunning food presentations for culinary innovation.",
    "category": "Culinary & Nutrition",
    "job": "culinary-innovation",
    "example_prompt": "Create a fusion dish combining Japanese ramen with Mexican mole sauce. Include 4-6 servings, detailed nutritional analysis, step-by-step cooking instructions, and presentation suggestions. Ensure the recipe balances umami, spice, and texture.",
    "example_result": "Culinary Innovation Complete!\n\n## üå∂Ô∏è Fusion Creation: Ramen-Mole Rhapsody\n\n### 1. Ingredient Fusion Research (Computer Controller Extension)\n\n**Global Ingredient Analysis:**\n- **Japanese Base**: Tonkotsu broth, fresh ramen noodles, nori, green onions\n- **Mexican Fusion**: Mole sauce components (chocolate, chili peppers, nuts, spices)\n- **Bridge Elements**: Sesame seeds, lime, cilantro for flavor harmony\n\n**Sourced Recipes:**\n- Authentic tonkotsu ramen from 15 Japanese sources\n- Traditional mole poblano from 8 Mexican culinary databases\n- Nutritional data from USDA and international food composition tables\n\n### 2. Nutritional Engineering (Developer Extension)\n\n**Macronutrient Balance Calculation:**\n```python\n# Nutritional optimization algorithm\ntarget_profile = {\n    'protein': 25-30g per serving,\n    'carbs': 45-55g per serving,\n    'fat': 15-20g per serving,\n    'fiber': 8-12g per serving\n}\n\ndef optimize_recipe(ingredients, servings=4):\n    total_nutrition = calculate_total_nutrition(ingredients)\n    per_serving = total_nutrition / servings\n    \n    # Adjust ratios for balance\n    if per_serving['protein'] < 25:\n        add_protein_sources()\n    if per_serving['fiber'] < 8:\n        add_fiber_elements()\n    \n    return optimized_recipe\n```\n\n**Per Serving Nutrition (4 servings):**\n- Calories: 485 kcal\n- Protein: 28g (23%)\n- Carbohydrates: 52g (43%)\n- Fat: 18g (34%)\n- Fiber: 9.2g\n- Sodium: 1,240mg\n- Key Micronutrients: Iron 4.2mg, Vitamin C 45mg, Calcium 180mg\n\n### 3. Culinary Visualization (Auto Visualiser Extension)\n\n**Generated Assets:**\n- Ingredient fusion diagram showing flavor profiles\n- Step-by-step cooking timeline visualization\n- Nutritional breakdown pie chart\n- Final dish presentation mockup\n- Flavor wheel analysis (umami, sweet, spicy, sour balance)\n\n**Presentation Design:**\n- Layered bowl composition with broth base\n- Mole-infused noodles draped elegantly\n- Garnish constellation of sesame, nori, and lime\n- Color palette: Deep mahogany broth, vibrant green accents\n\n### 4. Recipe Memory Bank (Memory Extension)\n\n**Stored Innovation Data:**\n- Complete recipe with variations indexed\n- Nutritional profiles cached for similar fusions\n- Cooking technique preferences saved\n- Flavor combinations cataloged for future reference\n\n**Recipe Evolution Tracking:**\n- Version 1.0: Initial fusion\n- Version 1.1: Nutritional optimization\n- Version 1.2: Presentation refinement\n\n## üìã Complete Recipe: Ramen-Mole Rhapsody\n\n### Ingredients (4 servings)\n**Broth Base:**\n- 2 cups tonkotsu-style pork broth\n- 1 cup mole sauce (store-bought or homemade)\n- 2 tbsp miso paste\n- 1 tbsp sesame oil\n\n**Proteins:**\n- 12 oz fresh ramen noodles\n- 8 oz pork belly, thinly sliced\n- 4 soft-boiled eggs\n\n**Vegetables & Aromatics:**\n- 4 green onions, finely sliced\n- 2 sheets nori, cut into strips\n- 1 lime, quartered\n- Fresh cilantro, chopped\n\n**Fusion Spices:**\n- 1 tsp cumin\n- 1 tsp coriander\n- ¬Ω tsp cinnamon\n- 2 dried ancho chiles\n\n### Cooking Instructions\n\n**Phase 1: Broth Fusion (25 minutes)**\n1. Heat tonkotsu broth to simmer\n2. Whisk in mole sauce gradually\n3. Add miso paste and sesame oil\n4. Infuse with fusion spices\n5. Simmer 20 minutes for flavor marriage\n\n**Phase 2: Protein Preparation (15 minutes)**\n1. Cook pork belly until crispy\n2. Soft-boil eggs (6 minutes)\n3. Prepare ramen noodles al dente\n\n**Phase 3: Assembly (5 minutes)**\n1. Divide noodles into bowls\n2. Pour hot fusion broth over noodles\n3. Top with pork belly and halved eggs\n4. Garnish with green onions, nori, and cilantro\n5. Serve with lime wedges\n\n### Flavor Profile Analysis\n- **Umami Depth**: Mole's chocolate + miso + pork = 9/10\n- **Spice Balance**: Ancho chiles + cumin provide gentle heat\n- **Texture Harmony**: Crispy pork, tender noodles, rich broth\n- **Cultural Fusion**: Japanese precision meets Mexican passion\n\n### Presentation Tips\n- Serve in deep bowls for broth immersion\n- Create height with egg positioning\n- Use contrasting colors for visual appeal\n- Add edible flowers for elegance\n\n## Innovation Metrics\n\n‚úÖ **Novelty Score**: 8.5/10 (unique flavor combination)\n‚úÖ **Nutritional Balance**: Optimized macronutrients\n‚úÖ **Cultural Fusion**: Japanese-Mexican synthesis\n‚úÖ **Scalability**: Adaptable for restaurant or home\n‚úÖ **Sustainability**: Uses accessible, seasonal ingredients\n\n## Next Culinary Experiments\n\n1. **Variation Ideas**:\n   - Vegan version with mushroom broth\n   - Seafood fusion with mole-marinated shrimp\n   - Spicy level adjustments\n\n2. **Scaling Options**:\n   - Restaurant portion (increase by 3x)\n   - Meal prep version (batch cooking)\n   - Dietary adaptations (keto, gluten-free)\n\n3. **Advanced Techniques**:\n   - Molecular gastronomy elements\n   - Fermentation integration\n   - International spice substitutions\n\nWould you like me to:\n- Create another fusion recipe?\n- Analyze nutritional variations?\n- Generate a restaurant menu?\n- Design plating photography?",
    "extensions": [
      {
        "name": "Computer Controller",
        "description": "Researches global recipes, nutritional databases, and culinary techniques from international sources.",
        "is_builtin": true,
        "environmentVariables": []
      },
      {
        "name": "Developer",
        "description": "Performs nutritional calculations, recipe scaling algorithms, and flavor profile optimization.",
        "is_builtin": true,
        "environmentVariables": []
      },
      {
        "name": "Auto Visualiser",
        "description": "Creates recipe visualizations, nutritional charts, and food presentation designs.",
        "is_builtin": true,
        "environmentVariables": []
      },
      {
        "name": "Memory",
        "description": "Stores innovative recipes, nutritional data, and culinary experiments for future reference and iteration.",
        "is_builtin": true,
        "environmentVariables": []
      }
    ]
  },
  {
    "id": "api-documentation-generator",
    "title": "API Documentation Generator",
    "description": "Generate comprehensive API documentation from code with interactive examples and detailed specifications",
    "category": "technical",
    "job": "engineering",
    "example_prompt": "Analyze my Express.js API code and generate comprehensive documentation. I have a REST API with endpoints for user management, authentication, and data operations. Create interactive documentation with examples for each endpoint, including request/response schemas, error codes, and authentication requirements.",
    "example_result": "I've analyzed your Express.js API and generated comprehensive documentation. Here's your complete API documentation:\n\n# API Documentation\n\n## Overview\n\n```yaml\nAPI Name: User Management API\nVersion: 1.0.0\nBase URL: https://api.yourapp.com/v1\nAuthentication: Bearer Token (JWT)\nContent-Type: application/json\n```\n\n## Authentication\n\nAll endpoints require authentication via JWT token in the Authorization header:\n\n```http\nAuthorization: Bearer <your-jwt-token>\n```\n\n## Endpoints\n\n### 1. User Management\n\n#### Create User\n```http\nPOST /api/users\n```\n\n**Request Body:**\n```json\n{\n  \"username\": \"string (required)\",\n  \"email\": \"string (required, valid email)\",\n  \"password\": \"string (required, min 8 chars)\",\n  \"firstName\": \"string (optional)\",\n  \"lastName\": \"string (optional)\",\n  \"role\": \"string (optional, default: 'user')\"\n}\n```\n\n**Example Request:**\n```bash\ncurl -X POST https://api.yourapp.com/v1/users \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\" \\\n  -d '{\n    \"username\": \"johndoe\",\n    \"email\": \"john@example.com\",\n    \"password\": \"securepassword123\",\n    \"firstName\": \"John\",\n    \"lastName\": \"Doe\"\n  }'\n```\n\n**Success Response (201):**\n```json\n{\n  \"success\": true,\n  \"data\": {\n    \"id\": \"507f1f77bcf86cd799439011\",\n    \"username\": \"johndoe\",\n    \"email\": \"john@example.com\",\n    \"firstName\": \"John\",\n    \"lastName\": \"Doe\",\n    \"role\": \"user\",\n    \"createdAt\": \"2025-01-15T10:30:00Z\",\n    \"updatedAt\": \"2025-01-15T10:30:00Z\"\n  },\n  \"message\": \"User created successfully\"\n}\n```\n\n**Error Responses:**\n```json\n// 400 Bad Request\n{\n  \"success\": false,\n  \"error\": {\n    \"code\": \"VALIDATION_ERROR\",\n    \"message\": \"Invalid input data\",\n    \"details\": [\n      {\n        \"field\": \"email\",\n        \"message\": \"Email format is invalid\"\n      }\n    ]\n  }\n}\n\n// 409 Conflict\n{\n  \"success\": false,\n  \"error\": {\n    \"code\": \"USER_EXISTS\",\n    \"message\": \"User with this email already exists\"\n  }\n}\n```\n\n#### Get User by ID\n```http\nGET /api/users/{id}\n```\n\n**Path Parameters:**\n- `id` (string, required): User ID\n\n**Example Request:**\n```bash\ncurl -X GET https://api.yourapp.com/v1/users/507f1f77bcf86cd799439011 \\\n  -H \"Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\"\n```\n\n**Success Response (200):**\n```json\n{\n  \"success\": true,\n  \"data\": {\n    \"id\": \"507f1f77bcf86cd799439011\",\n    \"username\": \"johndoe\",\n    \"email\": \"john@example.com\",\n    \"firstName\": \"John\",\n    \"lastName\": \"Doe\",\n    \"role\": \"user\",\n    \"createdAt\": \"2025-01-15T10:30:00Z\",\n    \"updatedAt\": \"2025-01-15T10:30:00Z\"\n  }\n}\n```\n\n#### Update User\n```http\nPUT /api/users/{id}\n```\n\n**Request Body:**\n```json\n{\n  \"firstName\": \"string (optional)\",\n  \"lastName\": \"string (optional)\",\n  \"email\": \"string (optional, valid email)\"\n}\n```\n\n#### Delete User\n```http\nDELETE /api/users/{id}\n```\n\n**Success Response (200):**\n```json\n{\n  \"success\": true,\n  \"message\": \"User deleted successfully\"\n}\n```\n\n### 2. Authentication\n\n#### Login\n```http\nPOST /api/auth/login\n```\n\n**Request Body:**\n```json\n{\n  \"email\": \"string (required)\",\n  \"password\": \"string (required)\"\n}\n```\n\n**Example Request:**\n```bash\ncurl -X POST https://api.yourapp.com/v1/auth/login \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"email\": \"john@example.com\",\n    \"password\": \"securepassword123\"\n  }'\n```\n\n**Success Response (200):**\n```json\n{\n  \"success\": true,\n  \"data\": {\n    \"token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\",\n    \"user\": {\n      \"id\": \"507f1f77bcf86cd799439011\",\n      \"username\": \"johndoe\",\n      \"email\": \"john@example.com\",\n      \"role\": \"user\"\n    },\n    \"expiresIn\": 3600\n  }\n}\n```\n\n#### Refresh Token\n```http\nPOST /api/auth/refresh\n```\n\n**Request Body:**\n```json\n{\n  \"refreshToken\": \"string (required)\"\n}\n```\n\n### 3. Data Operations\n\n#### Get All Items\n```http\nGET /api/items\n```\n\n**Query Parameters:**\n- `page` (number, optional): Page number (default: 1)\n- `limit` (number, optional): Items per page (default: 10, max: 100)\n- `sort` (string, optional): Sort field (default: 'createdAt')\n- `order` (string, optional): Sort order ('asc' or 'desc', default: 'desc')\n- `search` (string, optional): Search term\n\n**Example Request:**\n```bash\ncurl -X GET \"https://api.yourapp.com/v1/items?page=1&limit=20&sort=name&order=asc&search=example\" \\\n  -H \"Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\"\n```\n\n**Success Response (200):**\n```json\n{\n  \"success\": true,\n  \"data\": [\n    {\n      \"id\": \"507f1f77bcf86cd799439011\",\n      \"name\": \"Example Item\",\n      \"description\": \"This is an example item\",\n      \"price\": 29.99,\n      \"category\": \"electronics\",\n      \"createdAt\": \"2025-01-15T10:30:00Z\",\n      \"updatedAt\": \"2025-01-15T10:30:00Z\"\n    }\n  ],\n  \"pagination\": {\n    \"page\": 1,\n    \"limit\": 20,\n    \"total\": 150,\n    \"pages\": 8,\n    \"hasNext\": true,\n    \"hasPrev\": false\n  }\n}\n```\n\n## Error Codes\n\n| Code | HTTP Status | Description |\n|------|-------------|-------------|\n| `VALIDATION_ERROR` | 400 | Invalid input data |\n| `UNAUTHORIZED` | 401 | Authentication required |\n| `FORBIDDEN` | 403 | Insufficient permissions |\n| `NOT_FOUND` | 404 | Resource not found |\n| `USER_EXISTS` | 409 | User already exists |\n| `RATE_LIMITED` | 429 | Too many requests |\n| `SERVER_ERROR` | 500 | Internal server error |\n\n## Rate Limiting\n\n```yaml\nRate Limits:\n  Authentication: 5 requests per minute\n  General API: 100 requests per minute\n  File Upload: 10 requests per minute\n\nHeaders:\n  X-RateLimit-Limit: Request limit per window\n  X-RateLimit-Remaining: Remaining requests\n  X-RateLimit-Reset: Reset time (Unix timestamp)\n```\n\n## SDK Examples\n\n### JavaScript/Node.js\n```javascript\n// Using fetch\nconst response = await fetch('https://api.yourapp.com/v1/users', {\n  method: 'POST',\n  headers: {\n    'Content-Type': 'application/json',\n    'Authorization': `Bearer ${token}`\n  },\n  body: JSON.stringify({\n    username: 'johndoe',\n    email: 'john@example.com',\n    password: 'securepassword123'\n  })\n});\n\nconst data = await response.json();\n```\n\n### Python\n```python\nimport requests\n\nurl = 'https://api.yourapp.com/v1/users'\nheaders = {\n    'Content-Type': 'application/json',\n    'Authorization': f'Bearer {token}'\n}\ndata = {\n    'username': 'johndoe',\n    'email': 'john@example.com',\n    'password': 'securepassword123'\n}\n\nresponse = requests.post(url, headers=headers, json=data)\nresult = response.json()\n```\n\n### cURL Examples\n```bash\n# Create user\ncurl -X POST https://api.yourapp.com/v1/users \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -d '{\"username\":\"johndoe\",\"email\":\"john@example.com\",\"password\":\"secure123\"}'\n\n# Get user\ncurl -X GET https://api.yourapp.com/v1/users/507f1f77bcf86cd799439011 \\\n  -H \"Authorization: Bearer $TOKEN\"\n\n# Update user\ncurl -X PUT https://api.yourapp.com/v1/users/507f1f77bcf86cd799439011 \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -d '{\"firstName\":\"John\",\"lastName\":\"Smith\"}'\n```\n\n## Testing\n\n### Postman Collection\n```json\n{\n  \"info\": {\n    \"name\": \"User Management API\",\n    \"schema\": \"https://schema.getpostman.com/json/collection/v2.1.0/collection.json\"\n  },\n  \"item\": [\n    {\n      \"name\": \"Create User\",\n      \"request\": {\n        \"method\": \"POST\",\n        \"header\": [\n          {\n            \"key\": \"Content-Type\",\n            \"value\": \"application/json\"\n          }\n        ],\n        \"body\": {\n          \"mode\": \"raw\",\n          \"raw\": \"{\\\"username\\\":\\\"testuser\\\",\\\"email\\\":\\\"test@example.com\\\",\\\"password\\\":\\\"testpass123\\\"}\"\n        },\n        \"url\": {\n          \"raw\": \"{{base_url}}/users\",\n          \"host\": [\"{{base_url}}\"],\n          \"path\": [\"users\"]\n        }\n      }\n    }\n  ]\n}\n```\n\n## Changelog\n\n### Version 1.0.0 (2025-01-15)\n- Initial API release\n- User management endpoints\n- Authentication system\n- Basic CRUD operations\n\n---\n\n**Generated on:** 2025-01-15T10:30:00Z\n**API Version:** 1.0.0\n**Documentation Version:** 1.0.0\n\nWould you like me to:\n1. Generate OpenAPI/Swagger specification?\n2. Create Postman collection?\n3. Generate client SDKs?\n4. Add more detailed examples?\n5. Create API testing scripts?",
    "extensions": [
      {
        "name": "Developer",
        "command": "developer",
        "is_builtin": true,
        "environmentVariables": []
      }
    ]
  },
  {
    "id": "dev-api-endpoints-analysis",
    "title": "Analyze App Endpoints and Interfaces",
    "description": "Review application routing configuration and summarize all external interfaces",
    "category": "technical",
    "job": "engineering",
    "example_prompt": "Please analyze the application's routing configuration found in `config/routes.rb` and summarize all external interfaces, including API endpoints, service integrations, and public routes.",
    "example_result": "I've analyzed the routing configuration in config/routes.rb. Here's a summary of all external interfaces:\n\n1. API Endpoints (v1):\n```ruby\n# Authentication\nPOST   /api/v1/auth/login\nPOST   /api/v1/auth/refresh\nDELETE /api/v1/auth/logout\n\n# Users\nGET    /api/v1/users\nPOST   /api/v1/users\nGET    /api/v1/users/:id\nPATCH  /api/v1/users/:id\nDELETE /api/v1/users/:id\n\n# Products\nGET    /api/v1/products\nPOST   /api/v1/products\nGET    /api/v1/products/:id\n```\n\n2. Public Routes:\n- GET  / ‚Üí Pages#home\n- GET  /about ‚Üí Pages#about\n- GET  /contact ‚Üí Pages#contact\n- POST /contact ‚Üí Messages#create\n\n3. Service Integrations:\n- Stripe webhook: POST /webhooks/stripe\n- SendGrid events: POST /webhooks/sendgrid\n\n4. OAuth Providers:\n- GET /auth/google/callback\n- GET /auth/github/callback\n\nSecurity Notes:\n- All API endpoints require JWT authentication except /auth/login\n- Rate limiting applied to authentication endpoints\n- CORS configured for approved domains only\n- API versioning implemented via URL prefix",
    "extensions": [
      {
        "name": "Developer",
        "command": "developer",
        "is_builtin": true,
        "environmentVariables": []
      }
    ]
  },
  {
    "id": "asana-task-management",
    "title": "Manage Asana Tasks",
    "description": "Create, update, and manage Asana tasks and projects",
    "category": "productivity",
    "job": "project-management",
    "example_prompt": "Create a new task in my Asana workspace called 'Review Q4 metrics' and set the due date to next Friday. Then, find all tasks assigned to me that are due this week and summarize them.",
    "example_result": "I've completed the following actions in Asana:\n\n1. Created new task:\n- Title: \"Review Q4 metrics\"\n- Due date: Friday, April 4th\n- Status: Open\n- Project: Business Review\n\n2. Tasks due this week assigned to you:\n\n- Monday: \"Update sales dashboard\" (Marketing)\n- Tuesday: \"Team sync meeting notes\" (Team Management)\n- Wednesday: \"Client proposal review\" (Sales)\n- Thursday: \"Monthly budget reconciliation\" (Finance)\n- Friday: \"Review Q4 metrics\" (Business Review)\n\nAll tasks have been properly tagged and linked to their respective projects. I've also added the Q4 metrics task to your My Tasks list for easy access.",
    "extensions": [
      {
        "name": "Asana",
        "command": "npx -y @modelcontextprotocol/server-asana",
        "is_builtin": false,
        "environmentVariables": [
          {
            "name": "ASANA_ACCESS_TOKEN",
            "description": "Your Asana Personal Access Token.",
            "installation_notes": "Use OpenAI's GPT-4o was used for this prompt",
            "required": true
          }
        ]
      },
      {
        "name": "Computer Controller",
        "command": "computercontroller",
        "is_builtin": true,
        "environmentVariables": []
      }
    ]
  },
  {
    "id": "audio-summarizer",
    "title": "Generate Audio Summary from Webpage",
    "description": "Summarizes a webpage URL into bullet points and generates an MP3 audio file of the summary using ElevenLabs.",
    "category": "productivity",
    "job": "productivity",
    "example_prompt": "Hey goose , summarize the article at https://en.wikipedia.org/wiki/Coronavirus into short bulletpoints. Then, take that summary and generate an audio file using the ElevenLabs MCP with the 'Rachel' voice.",
    "example_result": "Based on the available content, here is a summarized version of the article about Coronavirus in bullet points:\n- Coronaviruses are a group of related viruses that cause diseases in mammals and birds.\n- In humans, coronaviruses can lead to respiratory tract infections, which can range from mild, like some cases of the common cold, to severe, such as SARS, MERS, and COVID-19.\n- The name \"coronavirus\" is derived from the Latin word \"corona,\" meaning \"crown\" or \"halo,\" which refers to the characteristic appearance of the virus particles.\n- Coronaviruses have a genome composed of a single strand of RNA and have characteristic surface spike proteins.\n- They are classified within the family Coronaviridae and the subfamily Orthocoronavirinae.\n- These viruses are further grouped into four genera: Alphacoronavirus, Betacoronavirus, Gammacoronavirus, and Deltacoronavirus.\n- Transmission between humans typically occurs through respiratory droplets, especially from coughs and sneezes.\n- Major outbreaks in recent history include the Severe Acute Respiratory Syndrome (SARS) in 2003, Middle East Respiratory Syndrome (MERS) in 2012, and COVID-19 starting in late 2019.\n\nNow, let's use the above summary to generate an audio file using the ElevenLabs MCP and the 'Rachel' voice. The audio file has been successfully generated using the 'Rachel' voice. You can find the file saved on your desktop under the name tts_Coron_20251029_145539.mp3.",
    "extensions": [
      {
        "name": "ElevenLabs MCP",
        "description": "Generates high-quality, human-sounding text-to-speech audio and AI voices.",
        "is_builtin": true,
        "environmentVariables": [
          {
            "name": "ELEVENLABS_API_KEY",
            "value": "",
            "required": true
          }
        ]
      }
    ]
  },
  {
    "id": "code-snippet-saver",
    "title": "Code Snippet Saver",
    "description": "Save useful code snippets with descriptions and tags so you can quickly recall and reuse them later across projects",
    "category": "productivity",
    "job": "engineering",
    "example_prompt": "Save this retry logic snippet: async function retry(fn, retries=3) { for(let i=0; i<retries; i++) { try { return await fn(); } catch(e) { if(i===retries-1) throw e; } } }",
    "example_result": "I'll help you save this retry logic snippet using the memory extension. Let me confirm the details:\n\n**Category**: \"javascript\" (since this is a JavaScript snippet)\n**Tags**: #retry #async #error-handling\n**Scope**: Would you like this to be stored globally (available across all projects) or locally (only for this project)?\n\nWould you like me to proceed with saving this snippet?",
    "extensions": [
      {
        "name": "memory",
        "command": "memory",
        "is_builtin": true,
        "environmentVariables": []
      }
    ]
  },
  {
    "id": "code-documentation-migrator",
    "title": "Code Documentation Migrator",
    "description": "Extract inline code documentation and comments from GitHub repositories and transform them into structured documentation site content with proper formatting and organization",
    "category": "technical",
    "job": "software-engineering",
    "example_prompt": "I need to migrate our project documentation from inline code comments to a proper documentation site. Here's what I need:\n\n1. Analyze the GitHub repository: https://github.com/myorg/myproject\n2. Extract all documentation from:\n   - README files\n   - Inline code comments (JSDoc, docstrings, etc.)\n   - Function and class documentation\n   - Architecture comments\n3. Organize the documentation into logical sections:\n   - Getting Started\n   - API Reference\n   - Architecture Overview\n   - Development Guide\n4. Generate markdown files for each section with proper formatting\n5. Create a table of contents and navigation structure\n6. Include code examples from the repository where relevant\n\nRepository language: JavaScript/TypeScript\nCurrent documentation state: Scattered across code comments and multiple README files\nTarget format: Markdown files for Docusaurus",
    "example_result": "I've successfully analyzed your repository and migrated the documentation. Here's what was created:\n\n## Documentation Structure Created\n\n```\ndocs/\n‚îú‚îÄ‚îÄ index.md (Home)\n‚îú‚îÄ‚îÄ getting-started/\n‚îÇ   ‚îú‚îÄ‚îÄ installation.md\n‚îÇ   ‚îú‚îÄ‚îÄ quick-start.md\n‚îÇ   ‚îî‚îÄ‚îÄ configuration.md\n‚îú‚îÄ‚îÄ api-reference/\n‚îÇ   ‚îú‚îÄ‚îÄ core-functions.md\n‚îÇ   ‚îú‚îÄ‚îÄ utilities.md\n‚îÇ   ‚îú‚îÄ‚îÄ types.md\n‚îÇ   ‚îî‚îÄ‚îÄ hooks.md\n‚îú‚îÄ‚îÄ architecture/\n‚îÇ   ‚îú‚îÄ‚îÄ overview.md\n‚îÇ   ‚îú‚îÄ‚îÄ data-flow.md\n‚îÇ   ‚îî‚îÄ‚îÄ components.md\n‚îú‚îÄ‚îÄ development/\n‚îÇ   ‚îú‚îÄ‚îÄ contributing.md\n‚îÇ   ‚îú‚îÄ‚îÄ testing.md\n‚îÇ   ‚îî‚îÄ‚îÄ deployment.md\n‚îî‚îÄ‚îÄ examples/\n    ‚îú‚îÄ‚îÄ basic-usage.md\n    ‚îî‚îÄ‚îÄ advanced-patterns.md\n```\n\n## Sample Generated Content\n\n### 1. Getting Started - Installation (docs/getting-started/installation.md)\n\n```markdown\n# Installation\n\n## Prerequisites\n\n- Node.js 18+ \n- npm or yarn\n- Git\n\n## Quick Install\n\n```bash\nnpm install myproject\n# or\nyarn add myproject\n```\n\n## Verify Installation\n\n```javascript\nimport { initialize } from 'myproject';\n\nconst app = initialize();\nconsole.log(app.version); // Should output version number\n```\n\n## Environment Setup\n\nCreate a `.env` file in your project root:\n\n```env\nAPI_KEY=your_api_key_here\nENVIRONMENT=development\n```\n\n## Next Steps\n\n- [Quick Start Guide](./quick-start.md)\n- [Configuration Options](./configuration.md)\n- [API Reference](../api-reference/core-functions.md)\n```\n\n### 2. API Reference - Core Functions (docs/api-reference/core-functions.md)\n\n```markdown\n# Core Functions\n\n## initialize()\n\nInitializes the application with default or custom configuration.\n\n**Signature:**\n```typescript\nfunction initialize(config?: Config): Application\n```\n\n**Parameters:**\n- `config` (optional): Configuration object\n  - `apiKey`: string - Your API key\n  - `environment`: 'development' | 'production'\n  - `debug`: boolean - Enable debug logging\n\n**Returns:** `Application` instance\n\n**Example:**\n```javascript\nimport { initialize } from 'myproject';\n\nconst app = initialize({\n  apiKey: process.env.API_KEY,\n  environment: 'production',\n  debug: false\n});\n```\n\n**Throws:**\n- `ConfigError` - When required configuration is missing\n- `InitializationError` - When initialization fails\n\n---\n\n## connect()\n\nEstablishes a connection to the remote service.\n\n**Signature:**\n```typescript\nasync function connect(options?: ConnectionOptions): Promise<Connection>\n```\n\n**Parameters:**\n- `options` (optional): Connection options\n  - `timeout`: number - Connection timeout in ms (default: 5000)\n  - `retry`: boolean - Enable auto-retry (default: true)\n  - `maxRetries`: number - Maximum retry attempts (default: 3)\n\n**Returns:** Promise resolving to `Connection` object\n\n**Example:**\n```javascript\nimport { connect } from 'myproject';\n\ntry {\n  const connection = await connect({\n    timeout: 10000,\n    retry: true\n  });\n  console.log('Connected:', connection.id);\n} catch (error) {\n  console.error('Connection failed:', error);\n}\n```\n\n---\n\n## process()\n\nProcesses input data and returns transformed output.\n\n**Signature:**\n```typescript\nfunction process(data: InputData): OutputData\n```\n\n**Parameters:**\n- `data`: Input data object\n  - `source`: string - Source identifier\n  - `payload`: any - Data payload\n  - `metadata`: object - Optional metadata\n\n**Returns:** Processed `OutputData` object\n\n**Example:**\n```javascript\nimport { process } from 'myproject';\n\nconst result = process({\n  source: 'api',\n  payload: { items: [1, 2, 3] },\n  metadata: { timestamp: Date.now() }\n});\n\nconsole.log(result.status); // 'success'\nconsole.log(result.data); // Processed items\n```\n```\n\n### 3. Architecture Overview (docs/architecture/overview.md)\n\n```markdown\n# Architecture Overview\n\n## System Design\n\nMyProject follows a modular, event-driven architecture designed for scalability and maintainability.\n\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ           Application Layer             ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ\n‚îÇ  ‚îÇ   API    ‚îÇ  ‚îÇ   CLI    ‚îÇ  ‚îÇ  SDK   ‚îÇ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n              ‚Üì\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ          Core Business Logic            ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ\n‚îÇ  ‚îÇ Processor‚îÇ  ‚îÇ Validator‚îÇ  ‚îÇ Handler‚îÇ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n              ‚Üì\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ           Data Layer                    ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ\n‚îÇ  ‚îÇ  Cache   ‚îÇ  ‚îÇ Database ‚îÇ  ‚îÇ Storage‚îÇ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n## Key Components\n\n### Application Layer\nHandles external interactions through multiple interfaces:\n- **API**: RESTful endpoints for programmatic access\n- **CLI**: Command-line interface for developers\n- **SDK**: Language-specific client libraries\n\n### Core Business Logic\nImplements the main application functionality:\n- **Processor**: Handles data transformation and processing\n- **Validator**: Ensures data integrity and business rules\n- **Handler**: Manages event processing and routing\n\n### Data Layer\nManages persistent and transient data:\n- **Cache**: Redis-based caching for performance\n- **Database**: PostgreSQL for relational data\n- **Storage**: S3-compatible object storage\n\n## Data Flow\n\n1. **Request Reception**: API/CLI receives user request\n2. **Validation**: Input data validated against schema\n3. **Processing**: Core logic processes the request\n4. **Data Access**: Required data fetched from data layer\n5. **Response**: Formatted response returned to client\n\n## Technology Stack\n\n- **Runtime**: Node.js 18+\n- **Language**: TypeScript 5.0+\n- **Framework**: Express.js\n- **Database**: PostgreSQL 15\n- **Cache**: Redis 7\n- **Testing**: Jest + Supertest\n- **CI/CD**: GitHub Actions\n\n## Design Patterns\n\n### Dependency Injection\nUsed throughout for loose coupling and testability.\n\n### Repository Pattern\nAbstracts data access logic from business logic.\n\n### Event-Driven\nComponents communicate via events for scalability.\n\n### Strategy Pattern\nPluggable processors for different data types.\n```\n\n### 4. Development Guide - Testing (docs/development/testing.md)\n\n```markdown\n# Testing Guide\n\n## Running Tests\n\n```bash\n# Run all tests\nnpm test\n\n# Run with coverage\nnpm run test:coverage\n\n# Run specific test file\nnpm test -- processor.test.js\n\n# Watch mode\nnpm test -- --watch\n```\n\n## Test Structure\n\n```javascript\n// Example: processor.test.js\nimport { process } from '../src/processor';\n\ndescribe('Processor', () => {\n  describe('process()', () => {\n    it('should process valid input successfully', () => {\n      const input = {\n        source: 'test',\n        payload: { value: 123 }\n      };\n      \n      const result = process(input);\n      \n      expect(result.status).toBe('success');\n      expect(result.data).toBeDefined();\n    });\n    \n    it('should handle invalid input gracefully', () => {\n      const input = { invalid: true };\n      \n      expect(() => process(input)).toThrow('Invalid input');\n    });\n  });\n});\n```\n\n## Testing Best Practices\n\n1. **Unit Tests**: Test individual functions in isolation\n2. **Integration Tests**: Test component interactions\n3. **E2E Tests**: Test complete user workflows\n4. **Coverage Target**: Maintain >80% code coverage\n5. **Mocking**: Use Jest mocks for external dependencies\n\n## Continuous Integration\n\nTests run automatically on:\n- Every pull request\n- Commits to main branch\n- Before deployment\n\n```yaml\n# .github/workflows/test.yml (excerpt)\nname: Tests\non: [push, pull_request]\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-node@v3\n      - run: npm install\n      - run: npm test\n      - run: npm run test:coverage\n```\n```\n\n### 5. Navigation Structure (sidebar.js)\n\n```javascript\nmodule.exports = {\n  docs: [\n    {\n      type: 'category',\n      label: 'Getting Started',\n      items: [\n        'getting-started/installation',\n        'getting-started/quick-start',\n        'getting-started/configuration'\n      ]\n    },\n    {\n      type: 'category',\n      label: 'API Reference',\n      items: [\n        'api-reference/core-functions',\n        'api-reference/utilities',\n        'api-reference/types',\n        'api-reference/hooks'\n      ]\n    },\n    {\n      type: 'category',\n      label: 'Architecture',\n      items: [\n        'architecture/overview',\n        'architecture/data-flow',\n        'architecture/components'\n      ]\n    },\n    {\n      type: 'category',\n      label: 'Development',\n      items: [\n        'development/contributing',\n        'development/testing',\n        'development/deployment'\n      ]\n    },\n    {\n      type: 'category',\n      label: 'Examples',\n      items: [\n        'examples/basic-usage',\n        'examples/advanced-patterns'\n      ]\n    }\n  ]\n};\n```\n\n## Migration Summary\n\n**Extracted Documentation From:**\n- 45 source files analyzed\n- 230+ inline comments processed\n- 12 README files consolidated\n- 67 function/class documentation blocks extracted\n- 23 architecture comments organized\n\n**Generated Documentation:**\n- 15 markdown files created\n- 4 main sections organized\n- Table of contents structured\n- Navigation sidebar configured\n- 34 code examples included\n- Cross-references added\n\n**Documentation Quality:**\n‚úÖ All public APIs documented\n‚úÖ Installation steps validated\n‚úÖ Code examples tested\n‚úÖ Links verified\n‚úÖ Formatting consistent\n‚úÖ Search optimized\n\n## Next Steps\n\n1. **Review Generated Content**: Check accuracy and completeness\n2. **Add Missing Sections**: Fill in any gaps identified\n3. **Add Images/Diagrams**: Enhance with visual aids where helpful\n4. **Set Up Doc Site**: Deploy to your documentation platform\n5. **Configure Search**: Set up search functionality\n6. **Add Versioning**: Implement docs versioning for releases\n\nWould you like me to:\n1. Generate additional sections?\n2. Create API reference from TypeScript types?\n3. Add interactive code playgrounds?\n4. Set up automated doc updates from code changes?",
    "extensions": [
      {
        "name": "GitHub",
        "command": "npx -y @modelcontextprotocol/server-github",
        "is_builtin": false,
        "link": "https://block.github.io/goose/docs/mcp/github-mcp",
        "environmentVariables": [
          {
            "name": "GITHUB_PERSONAL_ACCESS_TOKEN",
            "description": "GitHub personal access token with repo access",
            "required": true
          }
        ]
      },
      {
        "name": "Developer",
        "command": "developer",
        "is_builtin": true,
        "environmentVariables": []
      }
    ]
  },
  {
    "id": "content-amplifier-pipeline",
    "title": "Content Amplifier Pipeline",
    "description": "Transform YouTube educational content into multi-platform learning materials: extract transcripts, generate visual summaries, create dev.to articles, and deploy a companion website.",
    "category": "Content Transformation & Education",
    "job": "content-automation",
    "example_prompt": "Take this YouTube video about machine learning fundamentals and create a comprehensive learning package with article, visuals, and deployed website.",
    "example_result": "Content transformation complete! Here's what I created:\n\n1. Transcript Extraction (YouTube Transcript Extension):\n   - Extracted full transcript from 45-minute ML fundamentals video\n   - Identified key concepts and timestamps\n\n2. Visual Summary Creation (Auto Visualiser Extension):\n   - Generated 5 concept diagrams (neural networks, gradient descent, etc.)\n   - Created learning progress chart\n   - Saved visualizations to cloud\n\n3. Article Generation (Dev.to Extension):\n   - Published comprehensive article with code examples\n   - Added generated visualizations inline\n   - Article URL: dev.to/user/ml-fundamentals-explained\n\n4. Website Deployment (Vercel Extension):\n   - Created interactive learning site with transcript sections\n   - Embedded visualizations and code playground\n   - Live at: ml-fundamentals.vercel.app\n\nFeatures:\n‚úì End-to-end content transformation\n‚úì Multi-format output (visual, written, interactive)\n‚úì Automated deployment\n‚úì Cross-platform distribution\n\nNext steps:\n1. Share on Reddit's r/learnmachinelearning?\n2. Create PDF study guide?\n3. Generate speech narration?",
    "extensions": [
      {
        "name": "YouTube Transcript Extension",
        "description": "Extracts and processes YouTube video transcripts for analysis and transformation.",
        "is_builtin": false,
        "environmentVariables": []
      },
      {
        "name": "Auto Visualiser Extension",
        "description": "Automatically generates data visualizations and concept diagrams from text content.",
        "is_builtin": true,
        "environmentVariables": []
      },
      {
        "name": "Dev.to Extension",
        "description": "Creates and publishes technical articles on the Dev.to platform.",
        "is_builtin": false,
        "environmentVariables": []
      },
      {
        "name": "Vercel Extension",
        "description": "Deploys websites and web applications to Vercel's hosting platform.",
        "is_builtin": false,
        "environmentVariables": []
      }
    ]
  },
  {
    "id": "content-calendar-generator",
    "title": "Content Calendar Generator",
    "description": "Generate a content calendar with social media posts, blog topics, and email newsletters",
    "category": "productivity",
    "job": "marketing-content",
    "featured": true,
    "example_prompt": "Help me create a content calendar for the next month. I need:\n\n1. Social media posts (3 per week)\n2. Blog post topics (1 per week)\n3. Email newsletter ideas (2 per month)\n\nOur target audience is developers and tech professionals. Focus on topics around AI, developer tools, and productivity. Include suggested posting times and content types (image, video, text).",
    "example_result": "I've created a content calendar for next month. Here's the breakdown:\n\nWeek 1:\nSocial Media:\n- Monday 9am: \"üî• Just launched: Our new AI-powered code completion tool. Watch the demo! [Video]\"\n- Wednesday 2pm: \"Top 5 VS Code extensions for productivity in 2025 [Image carousel]\"\n- Friday 4pm: \"What's your go-to debugging technique? Share below! [Poll]\"\n\nBlog: \"The Future of AI Pair Programming: Beyond Code Completion\"\n\nWeek 2:\nSocial Media:\n- Monday 10am: \"Developer tip: Use these keyboard shortcuts to boost your workflow [Infographic]\"\n- Wednesday 3pm: \"Behind the scenes: How we optimized our CI/CD pipeline [Thread]\"\n- Friday 1pm: \"Weekend project: Build a ChatGPT plugin in 30 minutes [Tutorial link]\"\n\nBlog: \"Optimizing Docker Builds: A Practical Guide\"\n\nWeek 3:\nSocial Media:\n- Monday 9am: \"Meet our engineering team and their favorite dev tools [Team photo]\"\n- Wednesday 2pm: \"Quick tip: Debug faster with these console.log alternatives [Code snippet]\"\n- Friday 3pm: \"From monolith to microservices: Our journey [Case study]\"\n\nBlog: \"Security Best Practices for AI Applications\"\n\nWeek 4:\nSocial Media:\n- Monday 11am: \"New feature alert: AI-powered code review assistant [Demo video]\"\n- Wednesday 1pm: \"The evolution of JavaScript: 2015 vs 2025 [Comparison image]\"\n- Friday 4pm: \"What's your biggest coding pet peeve? [Interactive poll]\"\n\nBlog: \"Building Scalable Systems with Kubernetes and AI\"\n\nEmail Newsletters:\n1. Mid-month (15th):\nSubject: \"Level Up Your Dev Game: AI Tools Special\"\n- Feature story: The impact of AI on code review\n- Product updates\n- Community spotlight\n- Upcoming webinar announcement\n\n2. Month-end (30th):\nSubject: \"Monthly Dev Digest: Top Stories & Updates\"\n- Blog roundup\n- Most engaging social posts\n- Industry news\n- Developer resource of the month\n\nAll content has been added to your Google Calendar with reminders set 2 days before each posting date.",
    "extensions": [
      {
        "name": "Google Drive",
        "command": "npx -y @modelcontextprotocol/server-gdrive",
        "is_builtin": false,
        "link": "https://block.github.io/goose/v1/extensions/google-drive",
        "environmentVariables": [
          {
            "name": "GDRIVE_OAUTH_PATH",
            "description": "/Users/<username>/.config/gcp-oauth.keys.json",
            "required": true
          },
          {
            "name": "GDRIVE_CREDENTIALS_PATH",
            "description": "/Users/<username>/.config/.gdrive-server-credentials.json",
            "required": true
          }
        ]
      },
      {
        "name": "Computer Controller",
        "command": "computercontroller",
        "is_builtin": true,
        "environmentVariables": []
      }
    ]
  },
  {
    "id": "developer-data-model-design",
    "title": "Design and Validate Data Model",
    "description": "Transform requirements into a concrete data model implementation with validation",
    "category": "technical",
    "job": "data-analytics",
    "example_prompt": "I need help designing and prototyping a data model:\n1. Here's my verbal description of the data model requirements: We're building a task management system for a software development team. We need to track:\n- Projects with multiple tasks\n- Task assignments to team members\n- Task dependencies\n- Time estimates and actual time spent\n- Task status changes and history\n- Comments and attachments on tasks\n- Sprint/milestone assignments\n\n2. Can you help me transform this into a concrete implementation?\n\n3. Let's validate this against the following use cases:\n- Team lead creates a new project and adds initial tasks\n- Developer updates task status and logs time\n- QA adds a blocking issue that depends on another task\n- Manager generates sprint velocity report\n- Team member adds comments and attachments to tasks\n- System needs to track task history for auditing\n- Tasks need to be easily searchable by various criteria\n\n4. We'll need to be able to iterate on this design based on our findings",
    "example_result": "I've designed a data model based on your requirements. Here's the implementation:\n\n```sql\n-- Core tables\nCREATE TABLE projects (\n    id SERIAL PRIMARY KEY,\n    name VARCHAR(100) NOT NULL,\n    description TEXT,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\nCREATE TABLE users (\n    id SERIAL PRIMARY KEY,\n    email VARCHAR(255) UNIQUE NOT NULL,\n    name VARCHAR(100) NOT NULL,\n    role VARCHAR(50) NOT NULL\n);\n\nCREATE TABLE tasks (\n    id SERIAL PRIMARY KEY,\n    project_id INTEGER REFERENCES projects(id),\n    title VARCHAR(200) NOT NULL,\n    description TEXT,\n    status VARCHAR(50) NOT NULL,\n    priority VARCHAR(20),\n    estimated_hours DECIMAL(6,2),\n    actual_hours DECIMAL(6,2),\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\n-- Relationships and metadata\nCREATE TABLE task_assignments (\n    id SERIAL PRIMARY KEY,\n    task_id INTEGER REFERENCES tasks(id),\n    user_id INTEGER REFERENCES users(id),\n    assigned_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\nCREATE TABLE task_dependencies (\n    id SERIAL PRIMARY KEY,\n    dependent_task_id INTEGER REFERENCES tasks(id),\n    prerequisite_task_id INTEGER REFERENCES tasks(id),\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\nCREATE TABLE sprints (\n    id SERIAL PRIMARY KEY,\n    name VARCHAR(100) NOT NULL,\n    start_date DATE NOT NULL,\n    end_date DATE NOT NULL,\n    project_id INTEGER REFERENCES projects(id)\n);\n\nCREATE TABLE sprint_tasks (\n    sprint_id INTEGER REFERENCES sprints(id),\n    task_id INTEGER REFERENCES tasks(id),\n    PRIMARY KEY (sprint_id, task_id)\n);\n\n-- Activity tracking\nCREATE TABLE task_history (\n    id SERIAL PRIMARY KEY,\n    task_id INTEGER REFERENCES tasks(id),\n    user_id INTEGER REFERENCES users(id),\n    field_name VARCHAR(50) NOT NULL,\n    old_value TEXT,\n    new_value TEXT,\n    changed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\nCREATE TABLE time_logs (\n    id SERIAL PRIMARY KEY,\n    task_id INTEGER REFERENCES tasks(id),\n    user_id INTEGER REFERENCES users(id),\n    hours_spent DECIMAL(6,2) NOT NULL,\n    description TEXT,\n    logged_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\nCREATE TABLE comments (\n    id SERIAL PRIMARY KEY,\n    task_id INTEGER REFERENCES tasks(id),\n    user_id INTEGER REFERENCES users(id),\n    content TEXT NOT NULL,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\nCREATE TABLE attachments (\n    id SERIAL PRIMARY KEY,\n    task_id INTEGER REFERENCES tasks(id),\n    user_id INTEGER REFERENCES users(id),\n    file_name VARCHAR(255) NOT NULL,\n    file_path VARCHAR(512) NOT NULL,\n    file_size INTEGER NOT NULL,\n    mime_type VARCHAR(100) NOT NULL,\n    uploaded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n```\n\nValidation against use cases:\n\n1. Team Lead Creates Project:\n```sql\n-- Create project\nINSERT INTO projects (name, description) VALUES ('Mobile App v2', 'Version 2 of mobile app');\n\n-- Add initial tasks\nINSERT INTO tasks (project_id, title, status) \nVALUES (1, 'Setup CI/CD pipeline', 'TODO');\n```\n\n2. Developer Updates Task:\n```sql\n-- Update task status\nUPDATE tasks SET status = 'IN_PROGRESS' WHERE id = 1;\n\n-- Log time\nINSERT INTO time_logs (task_id, user_id, hours_spent, description)\nVALUES (1, 1, 2.5, 'Initial pipeline setup');\n```\n\n3. QA Adds Blocking Issue:\n```sql\n-- Create blocking issue\nINSERT INTO tasks (project_id, title, status)\nVALUES (1, 'Fix authentication bug', 'BLOCKED');\n\n-- Add dependency\nINSERT INTO task_dependencies (dependent_task_id, prerequisite_task_id)\nVALUES (2, 1);\n```\n\n4. Sprint Velocity Query:\n```sql\nSELECT \n    s.name as sprint_name,\n    COUNT(t.id) as total_tasks,\n    SUM(t.actual_hours) as total_hours,\n    AVG(t.actual_hours) as avg_hours_per_task\nFROM sprints s\nJOIN sprint_tasks st ON s.id = st.sprint_id\nJOIN tasks t ON st.task_id = t.id\nWHERE s.project_id = 1\nGROUP BY s.id, s.name;\n```\n\n5. Comments and Attachments:\n```sql\n-- Add comment\nINSERT INTO comments (task_id, user_id, content)\nVALUES (1, 2, 'Pipeline config updated in PR #123');\n\n-- Add attachment\nINSERT INTO attachments (task_id, user_id, file_name, file_path)\nVALUES (1, 2, 'pipeline-config.yml', '/uploads/123/pipeline-config.yml');\n```\n\n6. Task History Tracking:\n```sql\n-- Automatically tracked via trigger\nCREATE TRIGGER track_task_changes\nAFTER UPDATE ON tasks\nFOR EACH ROW\nEXECUTE FUNCTION log_task_change();\n```\n\n7. Task Search Indexes:\n```sql\n-- Create indexes for common search patterns\nCREATE INDEX idx_task_status ON tasks(status);\nCREATE INDEX idx_task_project ON tasks(project_id);\nCREATE INDEX idx_task_assignee ON task_assignments(user_id);\nCREATE INDEX idx_task_sprint ON sprint_tasks(sprint_id);\n```\n\nThis model supports all required functionality while maintaining data integrity and performance. The design is normalized to prevent data anomalies while including appropriate indexes for efficient querying.",
    "extensions": [
      {
        "name": "Developer",
        "command": "developer",
        "is_builtin": true,
        "environmentVariables": []
      },
      {
        "name": "Computer Controller",
        "command": "computercontroller",
        "is_builtin": true,
        "environmentVariables": []
      }
    ]
  },
  {
    "id": "ops-delivery-tracking",
    "title": "Real-Time Delivery Route Optimization",
    "description": "Monitor delivery routes and automatically optimize them based on real-time traffic conditions",
    "category": "business",
    "job": "operations",
    "example_prompt": "Track the live GPS location of driver ID #{driver_id}. Query Google Maps for real-time traffic data and adjust the estimated delivery time if delays exceed 5 minutes. If ETA changes, update the customer's live tracker and send an SMS notification. If the delay is greater than 20 minutes, check if another driver within a 1-mile radius can take over the delivery.",
    "example_result": "I've analyzed the delivery route for driver #1234. Here's the current status:\n\nCurrent Location:\n- Latitude: 37.7858\n- Longitude: -122.4064\n- Last Updated: 2 minutes ago\n\nRoute Analysis:\n- Original ETA: 2:45 PM\n- Current Traffic Conditions: Heavy congestion on Market St\n- Delay Detected: 12 minutes\n- New ETA: 2:57 PM\n\nActions Taken:\n1. Updated customer tracking portal\n2. Sent SMS to customer:\n   \"Your delivery is slightly delayed due to traffic. New ETA: 2:57 PM\"\n\nNearby Drivers:\n- Driver #1567: 0.8 miles away, 2 active deliveries\n- Driver #1892: 1.2 miles away, 1 active delivery\n\nRecommendation:\n- Delay is under 20 minutes threshold\n- Current driver should continue the delivery\n- Will continue monitoring and update if conditions change\n\nOptimized Route:\n```json\n{\n  \"original_route\": [\n    \"Market St\",\n    \"Van Ness Ave\",\n    \"Hayes St\"\n  ],\n  \"new_route\": [\n    \"Market St\",\n    \"Gough St\",\n    \"Hayes St\"\n  ],\n  \"estimated_time_saved\": \"8 minutes\"\n}\n```\n\nNext Steps:\n1. Driver has been notified of route change\n2. System will continue monitoring traffic conditions\n3. Next update in 5 minutes or if conditions change significantly",
    "extensions": [
      {
        "name": "Google Maps",
        "command": "npx -y @modelcontextprotocol/server-google-maps",
        "is_builtin": false,
        "environmentVariables": [
          {
            "name": "GOOGLE_MAPS_API_KEY",
            "description": "<YOUR_TOKEN>",
            "required": true
          }
        ]
      },
      {
        "name": "Computer Controller",
        "command": "computercontroller",
        "is_builtin": true,
        "environmentVariables": []
      }
    ]
  },
  {
    "id": "design-figma-to-code",
    "title": "Convert Designs to Code",
    "description": "Convert a Figma design into a web app",
    "category": "technical",
    "job": "design",
    "featured": true,
    "example_prompt": "Convert my figma design with file ID 7r0mLHWx2rrjwn79mcNVNE into a webpage. Get specific detailed information and styling about each element and components within each frame. Make sure to implement any interactions or animations and use a placeholder div with a gray background for images.\n\nSome elements are centralized, some are duplicated, make sure to get them correct. And ensure correct alignment and spacing between elements.",
    "example_result": "I've analyzed your Figma design and converted it into code. Here's the implementation:\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Landing Page</title>\n    <style>\n        .hero-section {\n            display: flex;\n            justify-content: space-between;\n            padding: 64px 120px;\n            background: linear-gradient(135deg, #F6F9FC 0%, #E9EEF3 100%);\n        }\n\n        .hero-content {\n            max-width: 540px;\n        }\n\n        .hero-title {\n            font-family: 'Inter';\n            font-weight: 700;\n            font-size: 48px;\n            line-height: 58px;\n            color: #1A1A1A;\n            margin-bottom: 24px;\n        }\n\n        .feature-grid {\n            display: grid;\n            grid-template-columns: repeat(3, 1fr);\n            gap: 32px;\n            padding: 80px 120px;\n        }\n\n        .feature-card {\n            background: #FFFFFF;\n            border-radius: 16px;\n            padding: 32px;\n            box-shadow: 0px 4px 12px rgba(0, 0, 0, 0.05);\n            transition: transform 0.3s ease;\n        }\n\n        .feature-card:hover {\n            transform: translateY(-8px);\n        }\n    </style>\n</head>\n<body>\n    <nav class=\"navbar\">\n        <!-- Navigation implementation -->\n    </nav>\n\n    <section class=\"hero-section\">\n        <div class=\"hero-content\">\n            <h1 class=\"hero-title\">Transform your workflow</h1>\n            <p class=\"hero-description\">Streamline your process with our intuitive platform</p>\n            <button class=\"cta-button\">Get Started</button>\n        </div>\n        <div class=\"hero-image\">\n            <!-- Placeholder for hero image -->\n            <div style=\"width: 480px; height: 320px; background: #E5E5E5; border-radius: 8px;\"></div>\n        </div>\n    </section>\n\n    <section class=\"feature-grid\">\n        <!-- Feature cards with hover animations -->\n        <div class=\"feature-card\">\n            <div class=\"icon\"><!-- Icon placeholder --></div>\n            <h3>Feature 1</h3>\n            <p>Description of feature 1</p>\n        </div>\n        <!-- Repeated for other features -->\n    </section>\n</body>\n</html>\n```\n\n```javascript\n// Animation and interaction implementations\ndocument.addEventListener('DOMContentLoaded', () => {\n    // Smooth scroll for navigation\n    document.querySelectorAll('a[href^=\"#\"]').forEach(anchor => {\n        anchor.addEventListener('click', function (e) {\n            e.preventDefault();\n            document.querySelector(this.getAttribute('href')).scrollIntoView({\n                behavior: 'smooth'\n            });\n        });\n    });\n\n    // Feature card hover effects\n    const cards = document.querySelectorAll('.feature-card');\n    cards.forEach(card => {\n        card.addEventListener('mouseenter', () => {\n            card.style.transform = 'translateY(-8px)';\n        });\n        card.addEventListener('mouseleave', () => {\n            card.style.transform = 'translateY(0)';\n        });\n    });\n});\n```\n\nImplementation Notes:\n1. Responsive Design\n   - Breakpoints set at 1200px, 992px, and 768px\n   - Mobile-first approach using flexbox and grid\n\n2. Styling Details\n   - Font: Inter (weights: 400, 500, 700)\n   - Color palette from Figma variables\n   - Shadow values matched exactly\n\n3. Animations\n   - Smooth hover transitions (0.3s ease)\n   - Scroll animations for sections\n   - Interactive elements with feedback\n\n4. Component Structure\n   - Modular CSS classes\n   - Semantic HTML5 elements\n   - Accessible markup with ARIA attributes\n\n5. Image Placeholders\n   - Gray background (#E5E5E5)\n   - Maintained aspect ratios\n   - Ready for asset replacement",
    "extensions": [
      {
        "name": "Developer",
        "command": "developer",
        "is_builtin": true,
        "environmentVariables": []
      },
      {
        "name": "Figma",
        "command": "npx -y @hapins/figma-mcp",
        "is_builtin": false,
        "environmentVariables": [
          {
            "name": "FIGMA_ACCESS_TOKEN",
            "description": "Figma API access token",
            "required": true
          }
        ]
      }
    ]
  },
  {
    "id": "operations-form-review-automation",
    "title": "Assign Reviewers to Conference Proposals",
    "description": "Automatically match incoming conference proposals with relevant track reviewers",
    "category": "business",
    "job": "operations",
    "example_prompt": "I need help building an automated monitoring system that will:\n1. Check an Airtable base every 10 minutes for new form submissions\n2. Match each submission with reviewer information stored in a Google Sheet\n3. Send me a notification with the submission details and assigned reviewer(s)\n4. Auto-dismiss the notification after 5 seconds\n\nCan you help me create this system, starting with setting up the necessary connections to Airtable and Google Sheets?",
    "example_result": "I'll help you create an automated monitoring system. Here's the implementation:\n\n1. First, let's create the monitoring script:\n\n```ruby\nrequire 'airrecords'\nrequire 'google_drive'\nrequire 'terminal-notifier'\n\n# Configure Airtable\nAirrecords.api_key = ENV['AIRTABLE_API_KEY']\nclass Submission < Airrecords::Table\n  self.base_key = 'your_base_id'\n  self.table_name = 'Submissions'\n\n  def self.new_submissions\n    all(filter: \"{Status} = 'New'\")\n  end\nend\n\n# Configure Google Drive\nsession = GoogleDrive::Session.from_config(\"config.json\")\nreviewers_sheet = session.spreadsheet_by_key(\"your_sheet_id\").worksheets[0]\n\n# Load reviewer data\ndef load_reviewers\n  reviewers = {}\n  reviewers_sheet.rows.each_with_index do |row, i|\n    next if i == 0 # Skip header\n    reviewers[row[1]] = {\n      name: row[0],\n      expertise: row[1].split(','),\n      current_load: row[2].to_i\n    }\n  end\n  reviewers\nend\n\n# Match submission with reviewers\ndef match_reviewers(submission, reviewers)\n  topic = submission['Topic']\n  matched_reviewers = reviewers.select do |_, r|\n    r[:expertise].include?(topic) && r[:current_load] < 3\n  end\n  matched_reviewers.sort_by { |_, r| r[:current_load] }.first(2)\nend\n\n# Main monitoring loop\nloop do\n  begin\n    reviewers = load_reviewers\n    new_submissions = Submission.new_submissions\n\n    new_submissions.each do |submission|\n      matched = match_reviewers(submission, reviewers)\n      \n      if matched.any?\n        # Update submission status\n        submission['Status'] = 'Assigned'\n        submission['Reviewers'] = matched.map { |_, r| r[:name] }.join(', ')\n        submission.save\n\n        # Send notification\n        message = \"New submission: #{submission['Title']}\\n\"\n        message += \"Assigned to: #{submission['Reviewers']}\"\n        \n        TerminalNotifier.notify(\n          message,\n          title: 'New Conference Proposal',\n          execute: 'open https://airtable.com/your_base_url',\n          timeout: 5\n        )\n      end\n    end\n\n  rescue => e\n    TerminalNotifier.notify(\n      \"Error: #{e.message}\",\n      title: 'Monitoring System Error'\n    )\n  end\n\n  sleep 600 # Wait 10 minutes\nend\n```\n\n2. Create a configuration file (config.json):\n\n```json\n{\n  \"client_id\": \"your_google_client_id\",\n  \"client_secret\": \"your_google_client_secret\",\n  \"scope\": [\n    \"https://www.googleapis.com/auth/drive\",\n    \"https://spreadsheets.google.com/feeds/\"\n  ],\n  \"refresh_token\": \"your_refresh_token\"\n}\n```\n\n3. Set up the launch agent (com.conference.monitor.plist):\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n<plist version=\"1.0\">\n<dict>\n    <key>Label</key>\n    <string>com.conference.monitor</string>\n    <key>ProgramArguments</key>\n    <array>\n        <string>/usr/bin/ruby</string>\n        <string>/path/to/monitor.rb</string>\n    </array>\n    <key>RunAtLoad</key>\n    <true/>\n    <key>KeepAlive</key>\n    <true/>\n    <key>StandardErrorPath</key>\n    <string>/tmp/conference.monitor.err</string>\n    <key>StandardOutPath</key>\n    <string>/tmp/conference.monitor.out</string>\n    <key>EnvironmentVariables</key>\n    <dict>\n        <key>AIRTABLE_API_KEY</key>\n        <string>your_airtable_api_key</string>\n    </dict>\n</dict>\n</plist>\n```\n\nImplementation Notes:\n\n1. Data Structure\n   - Airtable: Submissions table with Title, Topic, Status, Reviewers fields\n   - Google Sheet: Reviewers with Name, Expertise (comma-separated), Current Load\n\n2. Matching Logic\n   - Matches based on topic expertise\n   - Considers reviewer workload (max 3 assignments)\n   - Assigns 2 reviewers per submission\n\n3. Error Handling\n   - Catches and notifies on API errors\n   - Continues running after errors\n   - Logs to standard files\n\n4. Security\n   - Credentials stored in environment/config\n   - API keys not hardcoded\n   - Limited scope for Google access\n\n5. Monitoring\n   - Runs every 10 minutes\n   - Auto-restarts if crashed\n   - Clickable notifications to view details\n\nTo install:\n1. Save the script as monitor.rb\n2. Install required gems: `gem install airrecords google_drive terminal-notifier`\n3. Copy plist to ~/Library/LaunchAgents/\n4. Load with: `launchctl load ~/Library/LaunchAgents/com.conference.monitor.plist`",
    "extensions": [
      {
        "name": "Computer Controller",
        "command": "computercontroller",
        "is_builtin": true,
        "environmentVariables": []
      },
      {
        "name": "Google Drive",
        "command": "npx -y @modelcontextprotocol/server-gdrive",
        "is_builtin": false,
        "environmentVariables": [
          {
            "name": "GDRIVE_OAUTH_PATH",
            "description": "/Users/<username>/.config/gcp-oauth.keys.json / ",
            "required": true
          },
          {
            "name": "GDRIVE_CREDENTIALS_PATH",
            "description": "/Users/<username>/.config/.gdrive-server-credentials.json /",
            "required": true
          }
        ]
      }
    ]
  },
  {
    "id": "generate-storybook-entry",
    "title": "Generate Storybook Entry from Git Diff",
    "description": "Generate a Storybook documentation entry based on component changes in git diff",
    "category": "technical",
    "job": "engineering",
    "example_prompt": "Based on the current git diff, please generate a comprehensive Storybook entry for NavBar component that includes:\n\n1. Component description\n2. Props documentation\n3. Usage examples\n4. Edge cases and variations\n5. Accessibility considerations\n\nPlease format the output in MDX format suitable for Storybook.",
    "example_result": "Based on the git diff, I've generated a Storybook entry for the NavBar component:\n\n```mdx\nimport { Meta, Story, Canvas, ArgsTable } from '@storybook/addon-docs';\nimport { NavBar } from './NavBar';\n\n<Meta\n  title=\"Components/Navigation/NavBar\"\n  component={NavBar}\n  argTypes={{\n    variant: {\n      control: 'select',\n      options: ['primary', 'secondary', 'minimal'],\n      description: 'Visual style variant of the navbar'\n    },\n    isSticky: {\n      control: 'boolean',\n      description: 'Whether navbar stays fixed at top during scroll'\n    },\n    logo: {\n      control: 'text',\n      description: 'URL or path to logo image'\n    },\n    menuItems: {\n      control: 'object',\n      description: 'Array of navigation items'\n    }\n  }}\n/>\n\n# NavBar\n\nA responsive navigation bar component that adapts to different screen sizes and supports multiple visual styles.\n\n## Features\n\n- Responsive mobile menu with hamburger icon\n- Configurable navigation items\n- Optional sticky positioning\n- Multiple visual variants\n- Built-in search integration\n- Accessible keyboard navigation\n\n## Props\n\n<ArgsTable of={NavBar} />\n\n## Basic Usage\n\n<Canvas>\n  <Story name=\"Default\">\n    <NavBar\n      variant=\"primary\"\n      logo=\"/logo.svg\"\n      menuItems={[\n        { label: 'Home', href: '/' },\n        { label: 'Products', href: '/products' },\n        { label: 'About', href: '/about' }\n      ]}\n    />\n  </Story>\n</Canvas>\n\n## Variants\n\n### Secondary Style\n\n<Canvas>\n  <Story name=\"Secondary\">\n    <NavBar\n      variant=\"secondary\"\n      logo=\"/logo.svg\"\n      menuItems={[\n        { label: 'Home', href: '/' },\n        { label: 'Products', href: '/products' }\n      ]}\n    />\n  </Story>\n</Canvas>\n\n### Minimal Style\n\n<Canvas>\n  <Story name=\"Minimal\">\n    <NavBar\n      variant=\"minimal\"\n      menuItems={[\n        { label: 'Home', href: '/' },\n        { label: 'Products', href: '/products' }\n      ]}\n    />\n  </Story>\n</Canvas>\n\n## With Search\n\n<Canvas>\n  <Story name=\"WithSearch\">\n    <NavBar\n      variant=\"primary\"\n      showSearch={true}\n      onSearch={(term) => console.log(`Searching for: ${term}`)}\n      menuItems={[\n        { label: 'Home', href: '/' },\n        { label: 'Products', href: '/products' }\n      ]}\n    />\n  </Story>\n</Canvas>\n\n## Edge Cases\n\n### Long Menu Items\n\n<Canvas>\n  <Story name=\"LongItems\">\n    <NavBar\n      menuItems={[\n        { label: 'Home', href: '/' },\n        { label: 'Very Long Product Category Name That Might Wrap', href: '/products' },\n        { label: 'Another Really Long Navigation Item', href: '/about' }\n      ]}\n    />\n  </Story>\n</Canvas>\n\n### Many Items\n\n<Canvas>\n  <Story name=\"ManyItems\">\n    <NavBar\n      menuItems={Array(8).fill().map((_, i) => ({\n        label: `Item ${i + 1}`,\n        href: `#${i}`\n      }))}\n    />\n  </Story>\n</Canvas>\n\n## Accessibility\n\nThe NavBar component implements the following accessibility features:\n\n- Uses semantic HTML5 nav element\n- Implements ARIA landmarks for navigation\n- Keyboard navigation support (Tab, Enter, Space, Esc)\n- Mobile menu button follows ARIA menu button pattern\n- Color contrast meets WCAG 2.1 AA standards\n- Focus indicators visible in all themes\n\n### Keyboard Navigation\n\n- Tab: Move through navigation items\n- Enter/Space: Activate current item\n- Esc: Close mobile menu\n- Arrow keys: Navigate dropdown menus\n\n## Implementation Notes\n\n```tsx\n// Example TypeScript interfaces\ninterface MenuItem {\n  label: string;\n  href: string;\n  icon?: ReactNode;\n  children?: MenuItem[];\n}\n\ninterface NavBarProps {\n  variant?: 'primary' | 'secondary' | 'minimal';\n  isSticky?: boolean;\n  logo?: string;\n  menuItems: MenuItem[];\n  showSearch?: boolean;\n  onSearch?: (term: string) => void;\n}\n```\n\n## Best Practices\n\n1. Keep navigation items concise\n2. Limit top-level items to 7 or fewer\n3. Use consistent icons if implementing icon support\n4. Ensure dropdown menus are keyboard accessible\n5. Maintain mobile breakpoints in theme configuration\n```",
    "extensions": [
      {
        "name": "Developer",
        "command": "developer",
        "is_builtin": true,
        "environmentVariables": [
          {
            "name": "component_name",
            "description": "Name of the component to document",
            "required": true
          }
        ]
      }
    ]
  },
  {
    "id": "documentation-generate-toc",
    "title": "Generate Table of Contents for Repo",
    "description": "Generate a logically organized table of contents for a CONTRIBUTING.md file",
    "category": "technical",
    "job": "engineering",
    "example_prompt": "Analyze the CONTRIBUTING.md file and create a well-structured table of contents. Include all major sections and subsections, using consistent formatting and logical organization.",
    "example_result": "I've analyzed the CONTRIBUTING.md file and generated a table of contents. Here's the structured output:\n\n```markdown\n# Contributing to Project Name\n\n## Table of Contents\n\n1. [Getting Started](#getting-started)\n   - [Prerequisites](#prerequisites)\n   - [Development Environment](#development-environment)\n   - [Code Style Guide](#code-style-guide)\n\n2. [Development Workflow](#development-workflow)\n   - [Branching Strategy](#branching-strategy)\n   - [Commit Messages](#commit-messages)\n   - [Pull Requests](#pull-requests)\n   - [Code Review Process](#code-review-process)\n\n3. [Testing Guidelines](#testing-guidelines)\n   - [Unit Tests](#unit-tests)\n   - [Integration Tests](#integration-tests)\n   - [Performance Tests](#performance-tests)\n   - [Test Coverage Requirements](#test-coverage-requirements)\n\n4. [Documentation](#documentation)\n   - [Code Documentation](#code-documentation)\n   - [API Documentation](#api-documentation)\n   - [Example Usage](#example-usage)\n   - [Architecture Diagrams](#architecture-diagrams)\n\n5. [Release Process](#release-process)\n   - [Version Numbering](#version-numbering)\n   - [Release Checklist](#release-checklist)\n   - [Deployment Steps](#deployment-steps)\n\n6. [Community Guidelines](#community-guidelines)\n   - [Code of Conduct](#code-of-conduct)\n   - [Issue Reporting](#issue-reporting)\n   - [Feature Requests](#feature-requests)\n   - [Community Meetings](#community-meetings)\n\n7. [Support](#support)\n   - [Getting Help](#getting-help)\n   - [Troubleshooting](#troubleshooting)\n   - [FAQ](#faq)\n\n8. [Legal](#legal)\n   - [License](#license)\n   - [Contributor License Agreement](#contributor-license-agreement)\n   - [Third-party Dependencies](#third-party-dependencies)\n```\n\nImplementation Notes:\n\n1. Structure\n   - Organized in hierarchical order of engagement\n   - Maximum 3 levels deep for clarity\n   - Related topics grouped together\n\n2. Formatting\n   - Consistent indentation for subsections\n   - All sections properly linked\n   - Clear numbering system\n\n3. Navigation\n   - All links are lowercase, hyphenated\n   - Sections ordered by logical flow\n   - Progressive disclosure of information\n\n4. Coverage\n   - Technical aspects (development, testing)\n   - Process details (workflow, releases)\n   - Community aspects (guidelines, support)\n   - Legal requirements\n\n5. Maintainability\n   - Each section is distinct\n   - Easy to update and expand\n   - Follows standard markdown practices",
    "extensions": [
      {
        "name": "Developer",
        "command": "developer",
        "is_builtin": true,
        "environmentVariables": [
          {
            "name": "file_path",
            "description": "Path to the CONTRIBUTING.md file",
            "required": true
          }
        ]
      }
    ]
  },
  {
    "id": "get-all-available-tutorials",
    "title": "Get All Available Tutorials",
    "description": "Retrieve a list of all tutorials that are currently available in Goose",
    "category": "productivity",
    "job": "engineering",
    "example_prompt": "What type of tutorials are available for me to learn with goose?",
    "example_result": "Goose offers two tutorials to help you learn:\n1.  **Building an Extension with MCP (Model Context Protocol)**: This tutorial guides you through creating an extension for Goose using one of the available SDKs (Python, TypeScript, or Kotlin). You'll learn how to set up a server, implement resources, and create tools that the AI agent can use.\n2.  **Building Your First Game**: This tutorial provides a framework for building a simple game. The default suggestion is a Flappy Bird clone using Python and Pygame, but it can be adapted based on your preferences and experience. You'll cover environment setup, project structure, the core game loop, and game mechanics.\nWhich tutorial would you like to start with, or would you like more information about one of them?",
    "extensions": [
      {
        "name": "Tutorial",
        "command": "tutorial",
        "is_builtin": true,
        "environmentVariables": []
      }
    ]
  },
  {
    "id": "developer-github-branch-pr",
    "title": "Create a GitHub Branch and a Pull Request",
    "description": "Create a new branch, update README, and open a pull request on GitHub",
    "category": "technical",
    "job": "engineering",
    "example_prompt": "Create a new branch called hello-world in my angiejones/goose-demo repository. Update the README.md file to say \"this was written by goose\" and commit it. Open a pull request with your changes.",
    "example_result": "I've created a new feature branch and pull request:\n\n1. Branch Creation:\n```bash\n$ git checkout -b feature/user-authentication\n$ git add .\n$ git commit -m \"Add user authentication system\n\n- Implement JWT token handling\n- Add password hashing\n- Create login/logout endpoints\"\n$ git push origin feature/user-authentication\n```\n\n2. Pull Request Details:\n- Title: \"Feature: User Authentication System\"\n- Base: main ‚Üê feature/user-authentication\n- Status: Open\n\nDescription:\n```markdown\n## Changes\n- Implemented JWT-based authentication\n- Added secure password hashing using bcrypt\n- Created RESTful login/logout endpoints\n- Added user session management\n\n## Testing\n- Unit tests added for auth controllers\n- Integration tests for login flow\n- Security testing completed\n\n## Checklist\n- [x] Tests passing\n- [x] Security review completed\n- [x] Documentation updated\n```\n\nReviewers have been assigned and the CI pipeline is running.",
    "extensions": [
      {
        "name": "GitHub",
        "command": "npx -y @modelcontextprotocol/server-github",
        "is_builtin": false,
        "environmentVariables": [
          {
            "name": "GITHUB_PERSONAL_ACCESS_TOKEN",
            "description": "<YOUR_TOKEN>",
            "required": true
          }
        ]
      },
      {
        "name": "Developer",
        "command": "developer",
        "is_builtin": true,
        "environmentVariables": []
      }
    ]
  },
  {
    "id": "github-open-issues-analyzer",
    "title": "GitHub Open Issues Analyzer",
    "description": "Analyze a GitHub repository and summarize all open issues with labels, titles, assignees, and short main problems.",
    "category": "technical",
    "job": "software-engineering",
    "example_prompt": "Analyze the GitHub repository at [REPO_URL] and list all open issues.\n\nFor each issue, provide:\n- Labels\n- Title\n- Assignees\n- Short main problem (3‚Äì6 words summary)\n- URL and issue number\n\nOutput formats:\n1. Markdown table with columns: Label | Title | Assignees | Main Problem\n2. JSON\n\nInclude total number of open issues. Keep summaries short, clear, and readable.",
    "example_result": "## Open Issues\n\nTotal open issues: 1\n\n### Markdown Table\n\n| Label       | Title   | Assignees  | Main Problem        |\n|------------|---------|------------|---------------------|\n| enhancement | Button | Unassigned | Button not showing  |",
    "extensions": [
      {
        "name": "GitHub",
        "command": "goose session --with-streamable-http-extension \"https://api.githubcopilot.com/mcp/\"",
        "is_builtin": false,
        "link": "https://block.github.io/goose/docs/mcp/github-mcp",
        "environmentVariables": [
          {
            "name": "GITHUB_PERSONAL_ACCESS_TOKEN",
            "description": "GitHub personal access token with repo access",
            "required": true
          }
        ]
      },
      {
        "name": "Developer",
        "command": "developer",
        "is_builtin": true,
        "environmentVariables": []
      }
    ]
  },
  {
    "id": "hands-free-coding",
    "title": "Hands-free Coding",
    "description": "Use your voice to code",
    "category": "technical",
    "job": "engineering",
    "example_prompt": "I'd like to speak instead of typing",
    "example_result": "I'll help you code using voice commands. I'm now listening for your voice input.\n\nExample Voice Commands:\n\n\"Create a new Python function called calculate total that takes a list of numbers and returns their sum\"\n\n```python\ndef calculate_total(numbers):\n    return sum(numbers)\n```\n\n\"Add input validation to check if the list is empty\"\n\n```python\ndef calculate_total(numbers):\n    if not numbers:\n        raise ValueError(\"List cannot be empty\")\n    return sum(numbers)\n```\n\n\"Add a docstring explaining the function\"\n\n```python\ndef calculate_total(numbers):\n    \"\"\"Calculate the sum of a list of numbers.\n    \n    Args:\n        numbers (list): A list of numeric values\n        \n    Returns:\n        float: The sum of all numbers in the list\n        \n    Raises:\n        ValueError: If the input list is empty\n    \"\"\"\n    if not numbers:\n        raise ValueError(\"List cannot be empty\")\n    return sum(numbers)\n```\n\n\"Add a test case for the function\"\n\n```python\ndef test_calculate_total():\n    # Test normal case\n    assert calculate_total([1, 2, 3]) == 6\n    \n    # Test floating points\n    assert calculate_total([1.5, 2.5]) == 4.0\n    \n    # Test empty list\n    try:\n        calculate_total([])\n        assert False, \"Expected ValueError\"\n    except ValueError:\n        pass\n```\n\nVoice Command Tips:\n1. Speak clearly and pause between commands\n2. Use programming terms as you would write them\n3. Say \"undo\" to revert last change\n4. Say \"run tests\" to execute test cases\n5. Common commands:\n   - \"Create function/class\"\n   - \"Add parameter/argument\"\n   - \"Import library\"\n   - \"Add try-catch block\"\n   - \"Create for loop\"\n   - \"Add comment\"\n\nI'm still listening. What would you like to code next?",
    "extensions": [
      {
        "name": "Speech",
        "command": "uvx -p 3.10.14 speech-mcp@latest",
        "is_builtin": false,
        "installation_notes": "[PortAudio](https://github.com/GoogleCloudPlatform/python-docs-samples/blob/main/scripts/readme-gen/templates/install_portaudio.tmpl.rst#install-portaudio) is required for PyAudio to capture audio from your microphone",
        "environmentVariables": []
      },
      {
        "name": "Developer",
        "command": "developer",
        "is_builtin": true,
        "environmentVariables": []
      }
    ]
  },
  {
    "id": "image-resize",
    "title": "Resize Image with Aspect Ratio",
    "description": "Resize an image while maintaining aspect ratio and quality.",
    "category": "productivity",
    "job": "design",
    "example_prompt": "Resize my image {image_path} to be {width}x{height} pixels. Maintain the aspect ratio and image quality.",
    "example_result": "I'll help you resize the image while maintaining its aspect ratio and quality. Here's what I'll do:\n\n1. Load and analyze the original image:\n```python\nfrom PIL import Image\n\n# Open the image\nimg = Image.open('product_photo.jpg')\n\n# Get original dimensions\noriginal_width, original_height = img.size\nprint(f\"Original dimensions: {original_width}x{original_height}\")\n```\n\nOriginal dimensions: 2400x1600\n\n2. Calculate new dimensions preserving aspect ratio:\n```python\ntarget_width = 800\ntarget_height = 600\n\n# Calculate scaling factor\nwidth_ratio = target_width / original_width\nheight_ratio = target_height / original_height\nscale_factor = min(width_ratio, height_ratio)\n\n# Calculate new dimensions\nnew_width = int(original_width * scale_factor)\nnew_height = int(original_height * scale_factor)\n\nprint(f\"New dimensions: {new_width}x{new_height}\")\n```\n\nNew dimensions: 800x533\n\n3. Perform the resize operation:\n```python\n# Resize using high-quality Lanczos resampling\nresized_img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n\n# Save with optimal quality settings\nresized_img.save(\n    'product_photo_resized.jpg',\n    'JPEG',\n    quality=95,\n    optimize=True\n)\n```\n\nImage has been resized and saved as 'product_photo_resized.jpg'\n\nResize Summary:\n- Original size: 2400x1600 pixels\n- Target size: 800x600 pixels\n- Final size: 800x533 pixels\n- Aspect ratio: Maintained (1.5:1)\n- Resampling: Lanczos (high quality)\n- Format: JPEG\n- Quality: 95%\n- Optimization: Enabled\n\nThe image has been resized to fit within the requested dimensions while maintaining its original proportions. I used Lanczos resampling for the highest quality output and saved with optimal JPEG compression settings to preserve image quality.\n\nWould you like me to show you a preview of the resized image?",
    "extensions": [
      {
        "name": "Developer",
        "command": "developer",
        "is_builtin": true,
        "environmentVariables": []
      },
      {
        "name": "Computer Controller",
        "command": "computercontroller",
        "is_builtin": true,
        "environmentVariables": []
      }
    ]
  },
  {
    "id": "data-incident-analysis",
    "title": "Analyze PagerDuty Incident Patterns",
    "description": "Analyze incident data to identify patterns and opportunities for reducing alert noise",
    "category": "technical",
    "job": "engineering",
    "featured": true,
    "example_prompt": "Analyze the PagerDuty incident activity data to:\n1. Identify most frequent issues and their patterns\n2. Calculate incident frequencies and trends\n3. Determine if issues are ongoing or resolved\n4. Highlight top opportunities to reduce alert noise\n5. Generate recommendations for alert optimization\n\nThe analysis should focus on actionable insights to reduce unnecessary pages and improve on-call experience.",
    "example_result": "I've analyzed the PagerDuty incident data. Here's the comprehensive analysis:\n\n# Incident Analysis Report\n\n## 1. High-Frequency Issues\n\n```sql\nSELECT \n    incident_type,\n    COUNT(*) as occurrence_count,\n    AVG(resolution_time_minutes) as avg_resolution_time\nFROM incidents\nGROUP BY incident_type\nORDER BY occurrence_count DESC\nLIMIT 5;\n```\n\nTop 5 Most Frequent Issues:\n1. CPU Usage Spike (127 incidents)\n   - Peak times: 2-4 AM UTC\n   - Avg resolution: 12 minutes\n   - 92% auto-resolved\n\n2. Memory Warning (89 incidents)\n   - Consistent pattern on app-server-03\n   - Avg resolution: 8 minutes\n   - 95% auto-resolved\n\n3. API Response Time (67 incidents)\n   - Correlated with batch job schedule\n   - Avg resolution: 45 minutes\n   - 40% required manual intervention\n\n4. Disk Space Warning (52 incidents)\n   - Recurring on logging servers\n   - Avg resolution: 30 minutes\n   - 70% resolved by log rotation\n\n5. Connection Timeout (43 incidents)\n   - Database-related\n   - Avg resolution: 28 minutes\n   - 60% required manual intervention\n\n## 2. Temporal Analysis\n\n```python\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Incident frequency by hour\ndf['hour'] = pd.to_datetime(df['timestamp']).dt.hour\nhourlyCounts = df.groupby('hour')['incident_id'].count()\n\n# Plot distribution\nplt.figure(figsize=(12, 6))\nplt.bar(hourlyCounts.index, hourlyCounts.values)\nplt.title('Incident Distribution by Hour')\nplt.xlabel('Hour (UTC)')\nplt.ylabel('Number of Incidents')\n```\n\nKey Patterns:\n- 68% of alerts occur between 00:00-06:00 UTC\n- Wednesday shows highest incident rate\n- Month-end has 2.5x normal incident volume\n\n## 3. Issue Status Summary\n\nActive Issues:\n- Memory leaks on app-server-03\n  - Status: Under investigation\n  - Impact: Medium\n  - ETA: 48 hours\n\n- API response degradation\n  - Status: Partially mitigated\n  - Impact: Low\n  - ETA: 24 hours\n\nResolved Issues:\n- Database connection timeouts\n  - Resolution: Connection pool optimization\n  - Prevention: Added connection monitoring\n\n- Disk space warnings\n  - Resolution: Automated log rotation\n  - Prevention: Predictive cleanup jobs\n\n## 4. Alert Noise Reduction Opportunities\n\n1. High-Impact Opportunities:\n   ```\n   CPU Usage Alerts:\n   - Current: 127 alerts/month\n   - Potential: 15 alerts/month\n   - Reduction: 88%\n   - Effort: Low\n   ```\n\n2. Medium-Impact Opportunities:\n   ```\n   Memory Warnings:\n   - Current: 89 alerts/month\n   - Potential: 20 alerts/month\n   - Reduction: 78%\n   - Effort: Medium\n   ```\n\n## 5. Recommendations\n\n1. Immediate Actions:\n```yaml\n- Update CPU threshold:\n    from: 80% for 1 minute\n    to: 90% for 5 minutes\n    impact: -85% alerts\n\n- Implement memory alert aggregation:\n    window: 15 minutes\n    condition: Same host\n    impact: -70% alerts\n```\n\n2. Short-term Improvements:\n```yaml\n- Add context to API alerts:\n    - Include active connections\n    - Add recent deploy info\n    - Show batch job status\n\n- Enhance disk space monitoring:\n    - Predict fill rate\n    - Auto-trigger cleanup\n    - Weekly trend analysis\n```\n\n3. Long-term Projects:\n```yaml\n- Implement ML-based anomaly detection:\n    priority: High\n    effort: Large\n    benefits:\n      - 60% false positive reduction\n      - Automated threshold adjustment\n      - Pattern recognition\n\n- Develop unified alert dashboard:\n    priority: Medium\n    effort: Medium\n    features:\n      - Cross-service correlation\n      - Historical pattern view\n      - One-click suppression\n```\n\n## Implementation Plan\n\n1. Week 1-2:\n   - Adjust CPU thresholds\n   - Configure alert aggregation\n   - Update runbooks\n\n2. Week 3-4:\n   - Deploy enhanced monitoring\n   - Test new alert rules\n   - Train on-call team\n\n3. Month 2:\n   - Begin ML implementation\n   - Collect baseline metrics\n   - Develop dashboard\n\nExpected Outcomes:\n- 75% reduction in non-actionable alerts\n- 40% decrease in MTTR\n- 60% improvement in on-call satisfaction\n\nWould you like me to generate detailed configuration changes for any specific recommendation?",
    "extensions": [
      {
        "name": "Computer Controller",
        "command": "computercontroller",
        "is_builtin": true,
        "environmentVariables": []
      },
      {
        "name": "Developer",
        "command": "developer",
        "is_builtin": true,
        "environmentVariables": []
      }
    ]
  },
  {
    "id": "java-kotlin-test-migration",
    "title": "Migrate Java Tests to Kotlin",
    "description": "Select Java tests and migrate them to Kotlin, including compilation verification",
    "category": "technical",
    "job": "engineering",
    "example_prompt": "Please help migrate Java tests to Kotlin by:\n1. Finding and selecting 5 Java test files\n2. Converting each test to Kotlin while maintaining functionality\n3. Removing original Java files\n4. Verifying compilation with gradle\n5. Generating migration diffs\n\nFor each test file:\n- Create equivalent Kotlin test\n- Maintain test structure and assertions\n- Verify compilation success\n- Generate diff for review",
    "example_result": "I'll help you migrate the Java tests to Kotlin. Here's the migration process for one test file:\n\nOriginal Java Test:\n```java\n// UserServiceTest.java\nimport org.junit.jupiter.api.Test;\nimport static org.junit.jupiter.api.Assertions.*;\nimport static org.mockito.Mockito.*;\n\npublic class UserServiceTest {\n    private final UserRepository userRepository = mock(UserRepository.class);\n    private final EmailService emailService = mock(EmailService.class);\n    private final UserService userService = new UserService(userRepository, emailService);\n\n    @Test\n    public void createUser_WithValidData_ShouldSucceed() {\n        // Given\n        UserDTO userDTO = new UserDTO(\"john@example.com\", \"John Doe\");\n        User user = new User(userDTO.getEmail(), userDTO.getName());\n        when(userRepository.findByEmail(userDTO.getEmail())).thenReturn(null);\n        when(userRepository.save(any(User.class))).thenReturn(user);\n\n        // When\n        User result = userService.createUser(userDTO);\n\n        // Then\n        assertNotNull(result);\n        assertEquals(userDTO.getEmail(), result.getEmail());\n        assertEquals(userDTO.getName(), result.getName());\n        verify(emailService).sendWelcomeEmail(user);\n    }\n\n    @Test\n    public void createUser_WithExistingEmail_ShouldThrowException() {\n        // Given\n        UserDTO userDTO = new UserDTO(\"existing@example.com\", \"John Doe\");\n        when(userRepository.findByEmail(userDTO.getEmail()))\n            .thenReturn(new User(userDTO.getEmail(), \"Existing User\"));\n\n        // When/Then\n        assertThrows(UserAlreadyExistsException.class, () -> {\n            userService.createUser(userDTO);\n        });\n        verify(userRepository, never()).save(any());\n        verify(emailService, never()).sendWelcomeEmail(any());\n    }\n}\n```\n\nMigrated Kotlin Test:\n```kotlin\n// UserServiceTest.kt\nimport org.junit.jupiter.api.Test\nimport org.junit.jupiter.api.assertThrows\nimport org.mockito.kotlin.*\nimport kotlin.test.assertEquals\nimport kotlin.test.assertNotNull\n\nclass UserServiceTest {\n    private val userRepository: UserRepository = mock()\n    private val emailService: EmailService = mock()\n    private val userService = UserService(userRepository, emailService)\n\n    @Test\n    fun `create user with valid data should succeed`() {\n        // Given\n        val userDTO = UserDTO(email = \"john@example.com\", name = \"John Doe\")\n        val user = User(email = userDTO.email, name = userDTO.name)\n        whenever(userRepository.findByEmail(userDTO.email)).thenReturn(null)\n        whenever(userRepository.save(any())).thenReturn(user)\n\n        // When\n        val result = userService.createUser(userDTO)\n\n        // Then\n        assertNotNull(result)\n        assertEquals(userDTO.email, result.email)\n        assertEquals(userDTO.name, result.name)\n        verify(emailService).sendWelcomeEmail(user)\n    }\n\n    @Test\n    fun `create user with existing email should throw exception`() {\n        // Given\n        val userDTO = UserDTO(email = \"existing@example.com\", name = \"John Doe\")\n        whenever(userRepository.findByEmail(userDTO.email))\n            .thenReturn(User(email = userDTO.email, name = \"Existing User\"))\n\n        // When/Then\n        assertThrows<UserAlreadyExistsException> {\n            userService.createUser(userDTO)\n        }\n        verify(userRepository, never()).save(any())\n        verify(emailService, never()).sendWelcomeEmail(any())\n    }\n}\n```\n\nKey Changes Made:\n1. File Extension: .java ‚Üí .kt\n2. Class Declaration: Removed 'public'\n3. Test Methods:\n   - Removed 'public void'\n   - Added backtick names for readability\n   - Used Kotlin's string templates\n4. Assertions:\n   - Imported from kotlin.test\n   - Used Kotlin's assertThrows\n5. Mocking:\n   - Used mockito-kotlin extensions\n   - Replaced when/thenReturn with whenever\n6. Properties:\n   - Converted to Kotlin property syntax\n   - Used constructor parameter properties\n7. Named Parameters:\n   - Added for better readability\n   - Especially in object creation\n\nVerification Steps:\n```bash\n# Compile and test\n./gradlew :service:test --tests \"com.example.service.UserServiceTest\"\n\n# Test output\n> Task :service:test\nBUILD SUCCESSFUL in 3s\n4 actionable tasks: 4 executed\n```\n\nMigration Summary:\n1. ‚úÖ Syntax converted to idiomatic Kotlin\n2. ‚úÖ All tests passing\n3. ‚úÖ Maintained test coverage\n4. ‚úÖ Improved readability with Kotlin features\n5. ‚úÖ Verified with Gradle build\n\nWould you like me to proceed with migrating the remaining test files?",
    "extensions": [
      {
        "name": "Developer",
        "command": "developer",
        "is_builtin": true,
        "environmentVariables": []
      }
    ]
  },
  {
    "id": "developer-jetbrains-java-upgrade",
    "title": "Upgrade Java Project",
    "description": "Upgrade Java project to latest LTS version and refactor using newer features",
    "category": "technical",
    "job": "engineering",
    "example_prompt": "Using the JetBrains IDE tools, upgrade this project to use the latest Java LTS version and refactor the codebase to use newer Java features where beneficial.",
    "example_result": "I'll help you upgrade the Java project to the latest LTS version (Java 21) and refactor the code. Here's the process:\n\n1. Project Configuration Updates:\n\n```xml\n<!-- pom.xml -->\n<properties>\n    <java.version>21</java.version>\n    <maven.compiler.source>${java.version}</maven.compiler.source>\n    <maven.compiler.target>${java.version}</maven.compiler.target>\n</properties>\n```\n\n2. Example Refactoring - Before and After:\n\n```java\n// Before: Java 8 style code\npublic class OrderProcessor {\n    private final List<Order> orders = new ArrayList<>();\n    \n    public Optional<Order> findOrder(String id) {\n        return orders.stream()\n            .filter(order -> order.getId().equals(id))\n            .findFirst();\n    }\n    \n    public Map<String, List<Order>> groupByCustomer() {\n        Map<String, List<Order>> result = new HashMap<>();\n        for (Order order : orders) {\n            String customerId = order.getCustomerId();\n            if (!result.containsKey(customerId)) {\n                result.put(customerId, new ArrayList<>());\n            }\n            result.get(customerId).add(order);\n        }\n        return result;\n    }\n    \n    public double calculateTotal(List<Order> orders) {\n        double total = 0;\n        for (Order order : orders) {\n            total += order.getAmount();\n        }\n        return total;\n    }\n}\n```\n\n```java\n// After: Java 21 features\npublic class OrderProcessor {\n    private final List<Order> orders = new ArrayList<>();\n    \n    public Optional<Order> findOrder(String id) {\n        return orders.stream()\n            .filter(order -> order.id().equals(id))  // Record accessor\n            .findFirst();\n    }\n    \n    public Map<String, List<Order>> groupByCustomer() {\n        return orders.stream()\n            .collect(Collectors.groupingBy(Order::customerId));  // Method reference\n    }\n    \n    public double calculateTotal(List<Order> orders) {\n        return orders.stream()\n            .mapToDouble(Order::amount)\n            .sum();\n    }\n    \n    // New pattern matching for switch\n    public String getOrderStatus(Order order) {\n        return switch (order.status()) {\n            case PENDING when order.amount() > 1000 -> \"High-value pending\";\n            case PENDING -> \"Pending\";\n            case SHIPPED -> \"Shipped\";\n            case DELIVERED -> \"Delivered\";\n            case null -> throw new IllegalStateException(\"Status cannot be null\");\n        };\n    }\n    \n    // Records for DTOs\n    public record Order(\n        String id,\n        String customerId,\n        double amount,\n        Status status\n    ) {}\n    \n    public enum Status { PENDING, SHIPPED, DELIVERED }\n    \n    // Text blocks for SQL queries\n    private static final String FIND_ORDERS_SQL = \"\"\"\n        SELECT o.id, o.customer_id, o.amount, o.status\n        FROM orders o\n        WHERE o.customer_id = ?\n        AND o.status IN (?, ?)\n        ORDER BY o.created_at DESC\n        \"\"\";\n}\n```\n\n3. Build Configuration Updates:\n\n```groovy\n// build.gradle\nplugins {\n    id 'java'\n    id 'org.springframework.boot' version '3.2.0'\n}\n\njava {\n    sourceCompatibility = JavaVersion.VERSION_21\n    targetCompatibility = JavaVersion.VERSION_21\n}\n\ndependencies {\n    // Updated dependencies for Java 21\n    implementation 'org.springframework.boot:spring-boot-starter:3.2.0'\n    testImplementation 'org.junit.jupiter:junit-jupiter:5.10.0'\n}\n```\n\n4. IDE Configuration:\n\n```json\n// .idea/misc.xml\n{\n  \"project-jdk-name\": \"21\",\n  \"project-jdk-type\": \"JavaSDK\",\n  \"language-level\": \"21\"\n}\n```\n\n5. Migration Report:\n\nFeatures Upgraded:\n- Records for data classes\n- Pattern matching for switch\n- Text blocks for multiline strings\n- Enhanced type inference\n- Sealed classes where applicable\n- Virtual threads for concurrent operations\n\nStatistics:\n```\nFiles Modified: 47\nNew Features Used:\n- Records: 12 classes converted\n- Pattern Matching: 8 switch statements updated\n- Text Blocks: 15 SQL queries converted\n- Sealed Classes: 3 hierarchies implemented\n- Virtual Threads: 2 executors updated\n```\n\n6. Performance Impact:\n```\nBenchmark Results (JMH):\n- Startup Time: -15%\n- Memory Usage: -22%\n- Response Time: -8%\n- Throughput: +12%\n```\n\n7. Verification Steps:\n```bash\n# Compile and test\n./gradlew clean build\n\n# Run tests\n./gradlew test\n\n# Check for Java 21 compatibility\n./gradlew dependencyInsight --dependency java\n```\n\nWould you like me to:\n1. Show more refactoring examples?\n2. Generate migration scripts?\n3. Run compatibility tests?\n4. Update CI/CD configurations?",
    "extensions": [
      {
        "name": "JetBrains",
        "command": "npx -y @jetbrains/mcp-proxy",
        "is_builtin": false,
        "environmentVariables": []
      },
      {
        "name": "Developer",
        "command": "developer",
        "is_builtin": true,
        "environmentVariables": []
      }
    ]
  },
  {
    "id": "developer-js-express-setup",
    "title": "Scaffold JavaScript Boilerplate",
    "description": "Initialize a new JavaScript project with Express, Mongoose, Nodemon, and Dotenv",
    "category": "technical",
    "job": "engineering",
    "example_prompt": "Set up a new JavaScript project with Express, Mongoose, Nodemon, and Dotenv. Fetch the latest package versions, generate a README with those versions, and initialize Git",
    "example_result": "I'll help you set up a new JavaScript project with Express and related packages. Here's the step-by-step process:\n\n1. Initialize Project and Install Dependencies:\n\n```bash\n# Initialize project\nnpm init -y\n\n# Install dependencies\nnpm install express@4.18.2 mongoose@8.0.3 dotenv@16.3.1\nnpm install --save-dev nodemon@3.0.2\n```\n\n2. Project Structure:\n\n```\nproject-root/\n‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îú‚îÄ‚îÄ config/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ database.js\n‚îÇ   ‚îú‚îÄ‚îÄ models/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ User.js\n‚îÇ   ‚îú‚îÄ‚îÄ routes/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api.js\n‚îÇ   ‚îú‚îÄ‚îÄ middleware/\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ auth.js\n‚îÇ   ‚îî‚îÄ‚îÄ app.js\n‚îú‚îÄ‚îÄ .env\n‚îú‚îÄ‚îÄ .gitignore\n‚îú‚îÄ‚îÄ package.json\n‚îî‚îÄ‚îÄ README.md\n```\n\n3. Configuration Files:\n\n```javascript\n// src/config/database.js\nconst mongoose = require('mongoose');\n\nconst connectDB = async () => {\n  try {\n    const conn = await mongoose.connect(process.env.MONGODB_URI, {\n      useNewUrlParser: true,\n      useUnifiedTopology: true\n    });\n    console.log(`MongoDB Connected: ${conn.connection.host}`);\n  } catch (error) {\n    console.error(`Error: ${error.message}`);\n    process.exit(1);\n  }\n};\n\nmodule.exports = connectDB;\n```\n\n4. Main Application File:\n\n```javascript\n// src/app.js\nrequire('dotenv').config();\nconst express = require('express');\nconst connectDB = require('./config/database');\n\nconst app = express();\n\n// Connect to database\nconnectDB();\n\n// Middleware\napp.use(express.json());\napp.use(express.urlencoded({ extended: true }));\n\n// Routes\napp.use('/api', require('./routes/api'));\n\n// Error handling\napp.use((err, req, res, next) => {\n  console.error(err.stack);\n  res.status(500).send('Something broke!');\n});\n\nconst PORT = process.env.PORT || 3000;\napp.listen(PORT, () => {\n  console.log(`Server is running on port ${PORT}`);\n});\n```\n\n5. Example Route and Model:\n\n```javascript\n// src/models/User.js\nconst mongoose = require('mongoose');\n\nconst userSchema = new mongoose.Schema({\n  username: {\n    type: String,\n    required: true,\n    unique: true\n  },\n  email: {\n    type: String,\n    required: true,\n    unique: true\n  },\n  createdAt: {\n    type: Date,\n    default: Date.now\n  }\n});\n\nmodule.exports = mongoose.model('User', userSchema);\n```\n\n```javascript\n// src/routes/api.js\nconst express = require('express');\nconst router = express.Router();\nconst User = require('../models/User');\n\nrouter.post('/users', async (req, res) => {\n  try {\n    const user = new User(req.body);\n    await user.save();\n    res.status(201).json(user);\n  } catch (error) {\n    res.status(400).json({ error: error.message });\n  }\n});\n\nmodule.exports = router;\n```\n\n6. Environment Configuration:\n\n```env\n# .env\nPORT=3000\nMONGODB_URI=mongodb://localhost:27017/myapp\nNODE_ENV=development\n```\n\n7. Package.json Scripts:\n\n```json\n{\n  \"name\": \"express-mongoose-starter\",\n  \"version\": \"1.0.0\",\n  \"scripts\": {\n    \"start\": \"node src/app.js\",\n    \"dev\": \"nodemon src/app.js\",\n    \"test\": \"jest\"\n  },\n  \"dependencies\": {\n    \"express\": \"^4.18.2\",\n    \"mongoose\": \"^8.0.3\",\n    \"dotenv\": \"^16.3.1\"\n  },\n  \"devDependencies\": {\n    \"nodemon\": \"^3.0.2\"\n  }\n}\n```\n\n8. Git Configuration:\n\n```bash\n# Initialize Git\ngit init\n\n# Create .gitignore\ncat > .gitignore << EOL\nnode_modules/\n.env\n.DS_Store\nEOL\n\n# Initial commit\ngit add .\ngit commit -m \"Initial commit: Express project setup\"\n```\n\n9. README.md:\n\n```markdown\n# Express Mongoose Starter\n\nA modern Express.js application with MongoDB integration.\n\n## Features\n\n- Express.js 4.18.2 web framework\n- MongoDB integration with Mongoose 8.0.3\n- Environment variable support with Dotenv 16.3.1\n- Development server with Nodemon 3.0.2\n- Structured project layout\n- Basic error handling\n- API route examples\n\n## Getting Started\n\n1. Clone the repository\n2. Install dependencies: `npm install`\n3. Create .env file with required variables\n4. Start development server: `npm run dev`\n\n## Available Scripts\n\n- `npm start`: Production mode\n- `npm run dev`: Development mode with hot reload\n- `npm test`: Run tests\n\n## Project Structure\n\n[Project structure diagram as shown above]\n\n## API Endpoints\n\n- POST /api/users: Create new user\n- [Add more endpoints as developed]\n\n## Environment Variables\n\n- PORT: Server port (default: 3000)\n- MONGODB_URI: MongoDB connection string\n- NODE_ENV: Environment mode\n```\n\nThe project is now set up! Would you like me to:\n1. Add authentication middleware?\n2. Set up testing with Jest?\n3. Add more API endpoints?\n4. Configure CI/CD?",
    "extensions": [
      {
        "name": "Developer",
        "command": "developer",
        "is_builtin": true,
        "environmentVariables": []
      }
    ]
  },
  {
    "id": "voyp-make-call",
    "title": "Make a Phone Call",
    "description": "Have goose place a phone call",
    "category": "productivity",
    "job": "operations",
    "featured": true,
    "example_prompt": "Please call the number [phone number] and tell a joke",
    "example_result": "I'll help you make a phone call using VOYP. Here's what will happen:\n\n1. Call Initiation:\n```\nInitiating call to: +1 (XXX) XXX-XXXX\nStatus: Connecting...\n```\n\n2. Call Connected:\n```\nCall Status: Connected\nDuration: 00:00:03\n```\n\n3. Voice Interaction:\n```\nGoose: \"Hi there! I've got a programming joke for you:\n\nWhy do programmers always mix up Christmas and Halloween?\n\nBecause Oct 31 equals Dec 25!\"\n```\n\n4. Call Summary:\n```\nCall completed successfully\n- Duration: 32 seconds\n- Quality: Good\n- Recording: Available at voyp://calls/2025/03/31/call_12345.mp3\n```\n\nWould you like me to:\n1. Make another call?\n2. Tell a different joke?\n3. Save the recording?\n4. Schedule a follow-up call?",
    "extensions": [
      {
        "name": "VOYP",
        "command": "npx -y @voyp-mcp@0.1.0",
        "is_builtin": false,
        "link": "https://github.com/paulotaylor/voyp-mcp",
        "environmentVariables": [
          {
            "name": "VOYP_API_KEY",
            "description": "Your VOYP API Key",
            "required": true
          }
        ]
      }
    ]
  },
  {
    "id": "business-marketing-budget-review",
    "title": "Marketing Budget Review Meeting Prep",
    "description": "Prepare for marketing budget review meeting by analyzing Google Drive documents",
    "category": "business",
    "job": "marketing-content",
    "example_prompt": "I have an important marketing budget review meeting in 30 minutes and I need your help getting prepared. I have several documents in my Google Drive from our previous meetings and planning sessions. Could you help me by:\n\n1. Finding all relevant documents about our marketing budget and performance\n2. Giving me a quick summary of our Q1 performance\n3. Highlighting the key decisions we need to make about the marketing automation tool and video production\n4. Identifying any outstanding action items from our last meeting",
    "example_result": "I'll help you prepare for your marketing budget review meeting. Here's what I found:\n\n## 1. Relevant Documents Located\n\n```\nFound 4 relevant documents:\n1. Q1_2025_Marketing_Budget_Report.xlsx\n2. Marketing_Team_Meeting_Minutes_March15.docx\n3. Marketing_Automation_Tool_Comparison.pdf\n4. Video_Production_Quotes_2025.xlsx\n```\n\n## 2. Q1 2025 Performance Summary\n\n```\nBudget Overview:\n- Total Budget: $250,000\n- Spent: $228,500 (91.4%)\n- Remaining: $21,500\n\nKey Metrics vs Targets:\n‚úÖ Lead Generation: 2,450 (Target: 2,000)\n‚úÖ Cost per Lead: $48 (Target: $55)\n‚úÖ Conversion Rate: 3.8% (Target: 3.5%)\n‚ùå Customer Acquisition Cost: $380 (Target: $350)\n```\n\nChannel Performance:\n```\nPaid Search:\n- Budget: $80,000\n- Spent: $78,500\n- ROI: 2.8x\n\nSocial Media:\n- Budget: $60,000\n- Spent: $55,000\n- ROI: 3.2x\n\nContent Marketing:\n- Budget: $45,000\n- Spent: $42,000\n- ROI: 2.5x\n\nEvents:\n- Budget: $65,000\n- Spent: $53,000\n- ROI: 1.8x\n```\n\n## 3. Key Decisions Needed\n\n### Marketing Automation Tool\n```\nOptions on the table:\n1. HubSpot Enterprise\n   - Cost: $38,000/year\n   - Pros: Full integration, better reporting\n   - Cons: Higher cost, migration needed\n\n2. Marketo\n   - Cost: $29,000/year\n   - Pros: Advanced features, good API\n   - Cons: Steeper learning curve\n\n3. Current Tool + Upgrades\n   - Cost: $22,000/year\n   - Pros: No migration, team familiar\n   - Cons: Missing key features\n```\n\n### Video Production\n```\nProposals to consider:\n1. In-house Team\n   - Setup Cost: $45,000\n   - Annual Cost: $120,000\n   - Output: 8-10 videos/month\n\n2. Agency Partnership\n   - Monthly Retainer: $8,500\n   - Per Video: $2,000-$3,500\n   - Output: 4-6 videos/month\n\n3. Hybrid Model\n   - Basic in-house: $25,000\n   - Agency support: $5,000/month\n   - Output: 6-8 videos/month\n```\n\n## 4. Outstanding Action Items\n\nFrom March 15th Meeting:\n```\nUrgent (Due This Week):\n1. ‚è∞ Submit Q2 budget revision by Wednesday\n2. ‚è∞ Finalize marketing automation vendor shortlist\n\nHigh Priority:\n3. üìä Complete ROI analysis for video production options\n4. üìà Update campaign tracking for new privacy requirements\n\nPending Decisions:\n5. ü§ù Agency contract renewal (due in 45 days)\n6. üí∞ Budget reallocation for Q2 events\n```\n\n## Meeting Preparation Tips\n\n1. Key Discussion Points:\n```\n- Q1 overspend in paid search (-$3,500)\n- Successful social media experiments (+15% engagement)\n- Event budget underutilization (opportunity for reallocation)\n- Marketing automation tool ROI projections\n```\n\n2. Supporting Data to Reference:\n```\n- Lead quality scores by channel\n- Automation tool comparison matrix\n- Video production cost-benefit analysis\n- Updated marketing team structure\n```\n\n3. Recommended Agenda:\n```\n1. Q1 Performance Review (15 mins)\n2. Marketing Automation Decision (20 mins)\n3. Video Production Strategy (15 mins)\n4. Q2 Budget Adjustments (10 mins)\n```\n\nWould you like me to:\n1. Create a presentation with these key points?\n2. Generate a detailed cost comparison?\n3. Draft follow-up action items?\n4. Set up calendar reminders for deadlines?",
    "extensions": [
      {
        "name": "Google Drive",
        "command": "npx -y @modelcontextprotocol/server-gdrive",
        "is_builtin": false,
        "link": "https://block.github.io/goose/v1/extensions/google-drive",
        "environmentVariables": [
          {
            "name": "GDRIVE_OAUTH_PATH",
            "description": "/Users/<username>/.config/gcp-oauth.keys.json / ",
            "required": true
          },
          {
            "name": "GDRIVE_CREDENTIALS_PATH",
            "description": "/Users/<username>/.config/.gdrive-server-credentials.json /",
            "required": true
          }
        ]
      },
      {
        "name": "Computer Controller",
        "command": "computercontroller",
        "is_builtin": true,
        "environmentVariables": []
      }
    ]
  },
  {
    "id": "multi-channel-researcher",
    "title": "Multi-Channel Researcher",
    "description": "A workflow prompt that takes a topic and (1) searches the web, (2) summarizes key facts, and (3) drafts a social post. It demonstrates using multiple extensions in a single, multi-step flow.",
    "category": "Research & Content Creation",
    "job": "content-strategy",
    "example_prompt": "Research the impact of renewable energy on rural communities and draft a LinkedIn post.",
    "example_result": "I'll help you research and create a social post. Here's the workflow:\n\n1. Web Search (WebSearch extension):\n   - Searched for recent articles and reports on renewable energy in rural communities.\n   - Found 8 credible sources, including government reports and case studies.\n\n2. Summarization (TextSummarizer extension):\n   - Summarized the key benefits: job creation, energy independence, reduced costs.\n   - Highlighted challenges: infrastructure, funding, community engagement.\n   - Summary (150 words):\n     \"Renewable energy projects in rural communities drive economic growth, create jobs, and lower energy costs. However, success depends on infrastructure investment and active community participation. Government incentives and public-private partnerships are critical for overcoming funding barriers.\"\n\n3. Social Draft (SocialPublisher extension):\n   - Drafted a LinkedIn post:\n     \"Rural communities are harnessing renewable energy to boost local economies and create sustainable futures. Key benefits include job creation and lower costs, but success requires strong infrastructure and community engagement. #RenewableEnergy #RuralDevelopment #Sustainability\"\n\nFeatures:\n‚úì Multi-step workflow\n‚úì Combines research, summarization, and content creation\n‚úì Uses three extensions\n‚úì Output ready for publishing\n\nWould you like me to:\n1. Add source citations?\n2. Create a Twitter/X version?\n3. Generate a summary infographic?\n4. Save results to Google Drive?",
    "extensions": [
      {
        "name": "WebSearch",
        "description": "Searches the web for up-to-date information about a query.",
        "is_builtin": true,
        "environmentVariables": []
      },
      {
        "name": "TextSummarizer",
        "description": "Condenses multiple articles or texts into a short, clear summary.",
        "is_builtin": true,
        "environmentVariables": []
      },
      {
        "name": "SocialPublisher",
        "description": "Formats and drafts social media posts from given text or summaries.",
        "is_builtin": true,
        "environmentVariables": []
      }
    ]
  },
  {
    "id": "multi-project-security-audit",
    "title": "Multi-Project Security Audit",
    "description": "Perform comprehensive security analysis across multiple projects to identify and fix vulnerabilities",
    "category": "technical",
    "job": "engineering",
    "example_prompt": "Please analyze these codebases for security issues:\n\n1. Project Directories:\n- [Directory Path 1]\n- [Directory Path 2]\n- [Directory Path 3]\n\n2. Look for:\n- Hardcoded credentials (API keys, passwords, secrets)\n- Insecure cryptographic practices\n- SQL injection vulnerabilities\n- Exposed configuration files\n- Insecure session handling\n- Logging of sensitive data\n- Outdated dependencies\n- Unsafe authentication methods\n\n3. For each vulnerability found:\n- Show the problematic code\n- Explain the security risk\n- Provide a secure implementation\n- Help apply and test the fixes\n\n4. Create a detailed security report including:\n- Critical findings by project\n- Risk severity levels\n- File locations and snippets\n- Applied fixes and improvements\n- Verification steps taken",
    "example_result": "# Security Audit Report\n\n## Executive Summary\n\nAudit completed across 3 projects. Found:\n- 4 Critical vulnerabilities\n- 7 High-risk issues\n- 12 Medium-risk issues\n- 8 Low-risk concerns\n\n## Project 1: E-commerce API\n\n### Critical Findings\n\n1. Hardcoded AWS Credentials\n```python\n# /app/config/aws.py - Line 23\n# VULNERABLE CODE\naws_access_key = 'AKIA1234567890ABCDEF'\naws_secret_key = 'abcd1234EFGH5678ijkl9012mnop3456QRST7890'\n\n# SECURE IMPLEMENTATION\naws_access_key = os.environ.get('AWS_ACCESS_KEY')\naws_secret_key = os.environ.get('AWS_SECRET_KEY')\n\nif not all([aws_access_key, aws_secret_key]):\n    raise ConfigurationError('AWS credentials not properly configured')\n```\n\nRisk: Critical\n- Exposed credentials in version control\n- Potential unauthorized AWS access\n- Financial and data security implications\n\nFix Applied:\n```bash\n# 1. Removed credentials from code\n# 2. Added to environment variables\n# 3. Updated deployment configurations\n# 4. Rotated AWS keys\n```\n\n2. SQL Injection Vulnerability\n```python\n# /app/models/user.py - Line 156\n# VULNERABLE CODE\ndef find_by_username(username):\n    query = f\"SELECT * FROM users WHERE username = '{username}'\"\n    return db.execute(query)\n\n# SECURE IMPLEMENTATION\ndef find_by_username(username):\n    query = \"SELECT * FROM users WHERE username = %s\"\n    return db.execute(query, (username,))\n```\n\nRisk: Critical\n- SQL injection possible\n- Potential data breach\n- Unauthorized data access\n\n## Project 2: Admin Dashboard\n\n### High Risk Findings\n\n1. Insecure Session Configuration\n```javascript\n// /src/config/session.js - Line 45\n// VULNERABLE CODE\napp.use(session({\n  secret: 'my-secret-key',\n  resave: true,\n  saveUninitialized: true,\n  cookie: { secure: false }\n}));\n\n// SECURE IMPLEMENTATION\napp.use(session({\n  secret: process.env.SESSION_SECRET,\n  resave: false,\n  saveUninitialized: false,\n  cookie: {\n    secure: process.env.NODE_ENV === 'production',\n    httpOnly: true,\n    sameSite: 'strict',\n    maxAge: 3600000 // 1 hour\n  }\n}));\n```\n\n2. Outdated Dependencies\n```json\n// package.json\n{\n  \"dependencies\": {\n    \"express\": \"4.16.1\",        // Vulnerable version\n    \"moment\": \"2.24.0\",         // Known security issues\n    \"lodash\": \"4.17.15\"        // Multiple CVEs\n  }\n}\n```\n\nUpdated to:\n```json\n{\n  \"dependencies\": {\n    \"express\": \"4.18.2\",\n    \"moment\": \"2.29.4\",\n    \"lodash\": \"4.17.21\"\n  }\n}\n```\n\n## Project 3: Mobile API\n\n### High Risk Findings\n\n1. Insecure Password Hashing\n```java\n// /src/main/java/com/example/auth/PasswordUtil.java\n// VULNERABLE CODE\npublic String hashPassword(String password) {\n    return DigestUtils.md5Hex(password);\n}\n\n// SECURE IMPLEMENTATION\npublic String hashPassword(String password) {\n    return BCrypt.hashpw(password, BCrypt.gensalt(12));\n}\n```\n\n2. Sensitive Data Exposure\n```java\n// /src/main/java/com/example/logging/AuditLogger.java\n// VULNERABLE CODE\nlogger.info(\"User login: \" + username + \", password: \" + password);\n\n// SECURE IMPLEMENTATION\nlogger.info(\"User login attempt: {}\" username);\n```\n\n## Applied Security Improvements\n\n1. Dependency Updates\n```bash\n# Updated all projects to use latest secure versions\nnpm audit fix\ncomposer update\nmvn versions:use-latest-versions\n```\n\n2. Security Headers\n```javascript\n// Added security headers to all projects\napp.use(helmet());\napp.use(hpp());\napp.use(cors(corsOptions));\n```\n\n3. Input Validation\n```python\n# Added request validation\nfrom marshmallow import Schema, fields\n\nclass UserSchema(Schema):\n    username = fields.Str(required=True, validate=validate.Length(min=3))\n    email = fields.Email(required=True)\n```\n\n## Verification Steps\n\n1. Automated Testing\n```bash\n# Run security scans\nnpm audit\nbandit -r .\nSonarQube analysis\n\n# Run penetration tests\nOWASP ZAP scan\nBurp Suite tests\n```\n\n2. Manual Testing\n```\n‚úì SQL injection attempts\n‚úì XSS payload testing\n‚úì CSRF token verification\n‚úì Session handling checks\n‚úì Password policy enforcement\n```\n\n## Recommendations\n\n1. Immediate Actions:\n```\n- Rotate all exposed credentials\n- Update vulnerable dependencies\n- Enable WAF rules\n- Implement security headers\n```\n\n2. Short-term Improvements:\n```\n- Set up automated security scanning\n- Implement SAST/DAST in CI/CD\n- Add security test cases\n- Update security documentation\n```\n\n3. Long-term Strategy:\n```\n- Regular security training\n- Quarterly security audits\n- Threat modeling for new features\n- Bug bounty program\n```\n\nWould you like me to:\n1. Generate security patches?\n2. Create Jira tickets?\n3. Update security documentation?\n4. Schedule follow-up review?",
    "extensions": [
      {
        "name": "Filesystem",
        "command": "npx -y @modelcontextprotocol/server-filesystem",
        "is_builtin": false,
        "environmentVariables": []
      },
      {
        "name": "Developer",
        "command": "developer",
        "is_builtin": true,
        "environmentVariables": []
      }
    ]
  },
  {
    "id": "data-name-column-split",
    "title": "Clean Spreadsheet Data",
    "description": "Automatically organize messy data by splitting and reformatting columns",
    "category": "productivity",
    "job": "data-analytics",
    "example_prompt": "I'll help you split the names in Column C into separate First Name and Last Name columns. Let me analyze and modify your spreadsheet:\n\n1. First, I'll check the current structure of your spreadsheet\n2. Then I'll create a script to:\n   - Read the full names from Column C\n   - Split each name into first and last components\n   - Keep the first name in Column C\n   - Add the last names in Column D\n3. Finally, I'll save the changes back to your file\n\nPlease provide the path to your Excel file and I'll help you split the names.",
    "example_result": "I've analyzed your spreadsheet and will help split the names. Here's what I found and what I'll do:\n\n1. Current Structure Analysis:\n```\nSheet: Customer Data\nColumn C (Full Name): Contains 458 rows of data\nSample values:\n- John Smith\n- Mary Jane Wilson\n- Robert J. Anderson\n- Sarah Jean-Baptiste\n- O'Connor, Patrick\n```\n\n2. Data Cleaning Script:\n\n```python\nimport pandas as pd\n\ndef clean_and_split_names(df):\n    # Copy original data\n    df['Original Name'] = df['Full Name']\n    \n    # Handle reversed names (Last, First)\n    df['Full Name'] = df['Full Name'].apply(lambda x: \n        ' '.join(reversed(x.split(', '))) if ',' in x else x)\n    \n    # Split names into components\n    def split_name(name):\n        parts = name.split()\n        if len(parts) == 1:\n            return [parts[0], '']\n        elif len(parts) == 2:\n            return parts\n        else:\n            # Handle middle names/initials\n            return [parts[0], ' '.join(parts[1:])]\n    \n    # Apply splitting\n    df[['First Name', 'Last Name']] = pd.DataFrame(\n        df['Full Name'].apply(split_name).tolist(), \n        index=df.index\n    )\n    \n    return df\n\n# Read Excel file\ndf = pd.read_excel('customer_data.xlsx')\n\n# Process names\ndf = clean_and_split_names(df)\n\n# Save changes\ndf.to_excel('customer_data_updated.xlsx', index=False)\n```\n\n3. Results Summary:\n```\nProcessed 458 names:\n- Successfully split: 445\n- Special cases handled: 13\n  - Hyphenated surnames: 4\n  - Multiple surnames: 6\n  - Single names: 2\n  - Reversed format: 1\n```\n\n4. Sample Results:\n```\nBefore | After\n-------|-----------------------------------------------\nFull Name | First Name | Last Name | Original Name\n----------|------------|-----------|---------------\nJohn Smith | John | Smith | John Smith\nMary Jane Wilson | Mary | Jane Wilson | Mary Jane Wilson\nRobert J. Anderson | Robert | J. Anderson | Robert J. Anderson\nSarah Jean-Baptiste | Sarah | Jean-Baptiste | Sarah Jean-Baptiste\nO'Connor, Patrick | Patrick | O'Connor | O'Connor, Patrick\n```\n\n5. Data Quality Checks:\n```\n‚úì No empty cells created\n‚úì Special characters preserved\n‚úì Original data backed up\n‚úì Formatting maintained\n‚úì Column headers properly set\n```\n\n6. File Updates:\n```\n1. Added new columns:\n   - Column C: First Name\n   - Column D: Last Name\n   - Column E: Original Name (backup)\n\n2. Updated column headers\n3. Applied consistent formatting\n4. Added data validation\n```\n\nWould you like me to:\n1. Show more sample rows?\n2. Handle any special cases differently?\n3. Add additional data cleaning rules?\n4. Create a backup before saving?",
    "extensions": [
      {
        "name": "Computer Controller",
        "command": "computercontroller",
        "is_builtin": true,
        "environmentVariables": []
      },
      {
        "name": "Google Drive",
        "command": "npx -y @modelcontextprotocol/server-gdrive",
        "is_builtin": false,
        "environmentVariables": [
          {
            "name": "GDRIVE_OAUTH_PATH",
            "description": "/Users/<username>/.config/gcp-oauth.keys.json / ",
            "required": true
          },
          {
            "name": "GDRIVE_CREDENTIALS_PATH",
            "description": "/Users/<username>/.config/.gdrive-server-credentials.json /",
            "required": true
          }
        ]
      }
    ]
  },
  {
    "id": "developer-review-prep",
    "title": "Structure Your Performance Review",
    "description": "Sort collected feedback into a well-organized performance review",
    "category": "business",
    "job": "project-management",
    "example_prompt": "Create a web app that will take feedback and sort it into custom performance dimensions to populate a performance evaluation. The app should:\n- Allow users to define their review dimensions (e.g., Leadership, Technical Skills, Innovation)\n- Accept feedback text through input or file upload\n- Sort feedback into the defined dimensions\n- Export the organized feedback for performance reviews",
    "example_result": "I'll help you create a performance review organization app. Here's the implementation:\n\n1. Frontend Implementation (React):\n\n```jsx\n// src/components/ReviewOrganizer.js\nimport React, { useState } from 'react';\nimport { TextField, Button, Card, Chip } from '@mui/material';\n\nconst ReviewOrganizer = () => {\n  const [dimensions, setDimensions] = useState([\n    { id: 1, name: 'Leadership' },\n    { id: 2, name: 'Technical Skills' },\n    { id: 3, name: 'Innovation' }\n  ]);\n\n  const [feedback, setFeedback] = useState('');\n  const [organizedFeedback, setOrganizedFeedback] = useState({});\n\n  return (\n    <div className=\"p-6\">\n      <h1 className=\"text-2xl mb-4\">Performance Review Organizer</h1>\n      \n      {/* Dimension Management */}\n      <section className=\"mb-6\">\n        <h2 className=\"text-xl mb-2\">Review Dimensions</h2>\n        <div className=\"flex flex-wrap gap-2\">\n          {dimensions.map(dim => (\n            <Chip\n              key={dim.id}\n              label={dim.name}\n              onDelete={() => handleDeleteDimension(dim.id)}\n              className=\"m-1\"\n            />\n          ))}\n          <Button\n            variant=\"outlined\"\n            onClick={() => setShowDimensionDialog(true)}\n          >\n            Add Dimension\n          </Button>\n        </div>\n      </section>\n\n      {/* Feedback Input */}\n      <section className=\"mb-6\">\n        <h2 className=\"text-xl mb-2\">Input Feedback</h2>\n        <TextField\n          multiline\n          rows={4}\n          fullWidth\n          value={feedback}\n          onChange={(e) => setFeedback(e.target.value)}\n          placeholder=\"Paste feedback text here...\"\n        />\n        <input\n          type=\"file\"\n          accept=\".txt,.doc,.docx\"\n          onChange={handleFileUpload}\n          className=\"mt-2\"\n        />\n      </section>\n\n      {/* Organized Feedback */}\n      <section>\n        <h2 className=\"text-xl mb-2\">Organized Feedback</h2>\n        {dimensions.map(dim => (\n          <Card key={dim.id} className=\"p-4 mb-4\">\n            <h3 className=\"font-bold mb-2\">{dim.name}</h3>\n            <ul className=\"list-disc pl-4\">\n              {organizedFeedback[dim.id]?.map((item, i) => (\n                <li key={i} className=\"mb-2\">{item}</li>\n              ))}\n            </ul>\n          </Card>\n        ))}\n      </section>\n\n      <Button\n        variant=\"contained\"\n        color=\"primary\"\n        onClick={handleExport}\n        className=\"mt-4\"\n      >\n        Export Review\n      </Button>\n    </div>\n  );\n};\n```\n\n2. Backend Implementation (Node.js/Express):\n\n```javascript\n// src/server/feedbackAnalyzer.js\nconst natural = require('natural');\nconst classifier = new natural.BayesClassifier();\n\nclass FeedbackAnalyzer {\n  constructor(dimensions) {\n    this.dimensions = dimensions;\n    this.trainClassifier();\n  }\n\n  trainClassifier() {\n    // Training data for each dimension\n    const trainingData = {\n      Leadership: [\n        'leads by example',\n        'motivates team',\n        'decision making',\n        'delegation',\n        'team management'\n      ],\n      'Technical Skills': [\n        'problem solving',\n        'code quality',\n        'technical knowledge',\n        'debugging',\n        'architecture'\n      ],\n      Innovation: [\n        'creative solutions',\n        'new ideas',\n        'process improvement',\n        'initiative',\n        'experimentation'\n      ]\n    };\n\n    // Train classifier with examples\n    Object.entries(trainingData).forEach(([dimension, examples]) => {\n      examples.forEach(example => {\n        classifier.addDocument(example, dimension);\n      });\n    });\n\n    classifier.train();\n  }\n\n  analyzeFeedback(feedback) {\n    // Split feedback into sentences\n    const sentences = feedback.match(/[^.!?]+[.!?]+/g) || [feedback];\n\n    // Categorize each sentence\n    const categorized = {};\n    this.dimensions.forEach(dim => {\n      categorized[dim.id] = [];\n    });\n\n    sentences.forEach(sentence => {\n      const dimension = classifier.classify(sentence);\n      const dimId = this.dimensions.find(d => d.name === dimension)?.id;\n      if (dimId) {\n        categorized[dimId].push(sentence.trim());\n      }\n    });\n\n    return categorized;\n  }\n}\n```\n\n3. Export Template:\n\n```markdown\n# Performance Review Summary\nDate: {{date}}\nReviewer: {{reviewer}}\n\n## Leadership\n{{#leadership}}\n- {{.}}\n{{/leadership}}\n\n## Technical Skills\n{{#technical}}\n- {{.}}\n{{/technical}}\n\n## Innovation\n{{#innovation}}\n- {{.}}\n{{/innovation}}\n\n## Additional Notes\n{{notes}}\n\n## Development Plan\n1. Areas of Excellence:\n   {{#excellence}}\n   - {{.}}\n   {{/excellence}}\n\n2. Areas for Growth:\n   {{#growth}}\n   - {{.}}\n   {{/growth}}\n\n3. Action Items:\n   {{#actions}}\n   - {{.}}\n   {{/actions}}\n```\n\n4. Sample Usage:\n\nInput Feedback:\n```\nSarah has shown excellent leadership in the recent cloud migration project. \nShe effectively managed team resources and deadlines. Her technical \nknowledge of AWS services is impressive, and she implemented several \ninnovative solutions to reduce costs. Team members appreciate her clear \ncommunication and mentoring. She introduced a new CI/CD process that \nimproved deployment efficiency by 40%.\n```\n\nOrganized Output:\n```\nLeadership:\n- Effectively managed team resources and deadlines\n- Team members appreciate her clear communication and mentoring\n\nTechnical Skills:\n- Technical knowledge of AWS services is impressive\n- Implemented CI/CD process improving deployment efficiency\n\nInnovation:\n- Implemented several innovative solutions to reduce costs\n- Introduced new CI/CD process with 40% efficiency improvement\n```\n\n5. Features:\n\n```\n‚úì Custom dimensions\n‚úì Bulk text processing\n‚úì File upload support\n‚úì Natural language processing\n‚úì Export to multiple formats\n‚úì Data persistence\n‚úì Multi-user support\n```\n\nWould you like me to:\n1. Add more training data?\n2. Implement additional export formats?\n3. Add collaborative features?\n4. Create automated reminders?",
    "extensions": [
      {
        "name": "Developer",
        "command": "developer",
        "is_builtin": true,
        "environmentVariables": []
      },
      {
        "name": "Google Drive",
        "command": "npx -y @modelcontextprotocol/server-gdrive",
        "is_builtin": false,
        "environmentVariables": [
          {
            "name": "GDRIVE_OAUTH_PATH",
            "description": "/Users/<username>/.config/gcp-oauth.keys.json / ",
            "required": true
          },
          {
            "name": "GDRIVE_CREDENTIALS_PATH",
            "description": "/Users/<username>/.config/.gdrive-server-credentials.json /",
            "required": true
          }
        ]
      }
    ]
  },
  {
    "id": "pieces-stand-up-status-report",
    "title": "Create a status report for a stand-up meeting",
    "description": "Create a status report for a stand-up meeting, including 5 bullet points for what was accomplished yesterday. This is using the Pieces Long-Term Memory.",
    "category": "productivity",
    "job": "project-management",
    "example_prompt": "I need a status update for what I was using yesterday. Create a report with 5 bullet points based off the most important activities, and give each one a brief description.",
    "example_result": "Here's a report summarizing your key activities from yesterday, based on the most important interactions and applications you were using:\n\n1. Code Development with Goose:\n\tActivity: You worked on integrating SSE MCP servers into the Goose CLI, making enhancements to handle extensions via schema URLs.\n\tDescription: This task involved modifying code and testing new integrations to support advanced functionalities. It also included interactions with the Goose community on Discord for feedback and troubleshooting.\n\n2. Documentation Updates:\n\tActivity: You updated and managed documentation related to the Goose project and MCP integrations.\n\tDescription: This involved preparing documentation for new features, including usage guidelines and technical details, aiding in the improvement of user experience and technical instructions.\n\n3. Community Interaction on Discord:\n\tActivity: Engaged with the Block Open Source Community to discuss project developments and potential collaborations.\n\tDescription: You actively participated in community discussions, exchanging insights on project enhancements, and exploring collaborative opportunities with other developers and contributors.\n\n4. Managing and Testing Extensions:\n\tActivity: You focused on testing and managing various extensions through the Goose platform.\n\tDescription: This included configuring and validating different extensions, ensuring their compatibility and functionality, and incorporating feedback from testing.\n\n5. Content and Integration Planning:\n\tActivity: Planned integration workflows for MCP and documented their use cases.\n\tDescription: You worked on strategies for implementing MCP integrations effectively, involving planning sessions to optimize future project deployments and align them with user requirements and project objectives.\n\nThese activities demonstrate a productive day with a focus on development, collaboration, and content management within your technical community.",
    "extensions": [
      {
        "name": "Pieces",
        "url": "http://localhost:39300/model_context_protocol/2024-11-05/sse",
        "is_builtin": false
      }
    ]
  },
  {
    "id": "github-dev-pr-impact-analyzer",
    "title": "PR Impact Analysis Report",
    "description": "Analyzes pull requests using GitHub to fetch PR data and Developer to examine code changes, generating structured impact reports with risk assessment and review priorities",
    "category": "technical",
    "job": "engineering",
    "example_prompt": "Analyze PR #247 in myorg/backend-api. Use GitHub to fetch the PR details, diff, and commits. Then use Developer to analyze the code changes and identify: (1) what systems are affected, (2) potential risks or breaking changes, (3) missing tests, and (4) what reviewers should prioritize. Format as a structured report with actionable items.",
    "example_result": "# PR #247 Impact Analysis: Rate Limiting Implementation\n\n## Extension Integration\n1. **GitHub Extension** ‚Üí Fetched PR metadata, file diffs, and commit history\n2. **Developer Extension** ‚Üí Analyzed code changes, dependencies, and test coverage\n\n---\n\n## üìä Quick Summary\n- **Files Changed:** 12 (+456 / -89 lines)\n- **Author:** @sarah-dev\n- **Commits:** 8\n- **Overall Risk:** üü° MEDIUM\n\n## üéØ Systems Affected\n\n### Critical Impact\n**Authentication System** üî¥ HIGH RISK\n- Files: `src/auth/middleware.ts`, `src/auth/rate-limiter.ts`\n- Impact: All 40+ authenticated endpoints\n- Risk: Core auth flow modification\n\n**Database Schema** üü° MEDIUM RISK\n- Files: `migrations/2024_add_rate_limit_tracking.sql`\n- Impact: New table, affects backups\n- Risk: Requires migration coordination\n\n### Moderate Impact\n**API Responses** üü¢ LOW RISK\n- Files: `src/utils/response-formatter.ts`\n- Impact: New 429 status code handling\n- Risk: Isolated, backward compatible\n\n## ‚ö†Ô∏è Risks Detected\n\n### üî¥ Must Fix Before Merge\n1. **Redis Connection Pool**\n   - Issue: No connection pooling config\n   - Risk: Connection exhaustion under load\n   - Fix: Add `maxConnections` in `src/config/redis.ts`\n\n2. **Missing Tests**\n   - Issue: `rate-limiter.ts` has no test file\n   - Risk: Untested edge cases\n   - Fix: Add `__tests__/rate-limiter.test.ts`\n\n### üü° Should Address\n3. **Hardcoded Limits**\n   - Issue: Rate limits in code (line 45)\n   - Risk: Can't adjust per environment\n   - Fix: Move to `.env` config\n\n4. **API Contract**\n   - Issue: New `X-RateLimit-*` headers not documented\n   - Risk: Client compatibility\n   - Fix: Update OpenAPI spec\n\n## ‚úÖ What's Good\n- Clean module separation\n- Comprehensive logging\n- Redis fallback handling\n\n## üìã Review Checklist\n\n### Before Approval\n- [ ] Redis pool configuration added\n- [ ] Integration tests for rate limiter\n- [ ] Config moved to environment variables\n- [ ] API docs updated with new headers\n\n### Security Review\n- [ ] Rate limit bypass logic for admins\n- [ ] Error messages don't leak sensitive data\n- [ ] Database migration rollback tested\n\n### Performance Review\n- [ ] Load test with concurrent requests\n- [ ] Redis failover scenario tested\n- [ ] Monitor rate limit metrics in dashboard\n\n## üîó Dependencies\n```diff\n+ redis@4.6.7\n+ ioredis@5.3.2\n  express@4.18.2 ‚Üí 4.19.0 (security patch)\n```\n\n## üí° Action Items\n\n**For Author (@sarah-dev):**\n1. Add integration tests (high priority)\n2. Configure Redis connection pool\n3. Move rate limits to environment config\n4. Update API documentation\n\n**For Reviewers:**\n- @backend-lead: Security & auth flow review (30-45 min)\n- @devops: Redis infrastructure & migration (20 min)\n- @qa-team: Test coverage verification (15 min)\n\n**Estimated Review Time:** 45-60 minutes\n\n---\n**Analysis Method:**\n- GitHub extension fetched PR data, diffs, and commit metadata\n- Developer extension analyzed code structure, dependencies, and patterns\n- Cross-referenced changes against codebase architecture",
    "extensions": [
      {
        "name": "GitHub",
        "command": "docker",
        "args": [
          "run",
          "-i",
          "--rm",
          "-e",
          "GITHUB_PERSONAL_ACCESS_TOKEN",
          "ghcr.io/github/github-mcp-server"
        ],
        "is_builtin": false,
        "environmentVariables": [
          {
            "name": "GITHUB_PERSONAL_ACCESS_TOKEN",
            "description": "<YOUR_TOKEN>",
            "required": true
          }
        ]
      },
      {
        "name": "Developer",
        "command": "developer",
        "is_builtin": true,
        "environmentVariables": []
      }
    ]
  },
  {
    "id": "sales-product-region-lookup",
    "title": "Check Product Availability in Regions",
    "description": "Research which countries and regions a product is available in",
    "category": "business",
    "job": "project-management",
    "featured": true,
    "example_prompt": "List ISO 3166-1 country codes where {product_name} is sold. Return JSON containing:\ncountry_codes: List of the ISO-3166-1 country codes that are valid for this device\ndevice_model: The model you have performed the lookup for\nis_north_america: Whether or not the specified device is expected to acquired easily in north america",
    "example_result": "I've researched the regional availability for iPhone 14 Pro. Here's the analysis:\n\n```json\n{\n  \"device_model\": \"iPhone 14 Pro\",\n  \"country_codes\": [\n    \"AE\", \"AT\", \"AU\", \"BE\", \"BG\", \"BR\", \"CA\", \"CH\", \"CL\", \"CN\",\n    \"CO\", \"CY\", \"CZ\", \"DE\", \"DK\", \"EE\", \"ES\", \"FI\", \"FR\", \"GB\",\n    \"GR\", \"HK\", \"HR\", \"HU\", \"ID\", \"IE\", \"IL\", \"IN\", \"IT\", \"JP\",\n    \"KR\", \"LT\", \"LU\", \"LV\", \"MX\", \"MY\", \"NL\", \"NO\", \"NZ\", \"PH\",\n    \"PL\", \"PT\", \"RO\", \"SA\", \"SE\", \"SG\", \"SI\", \"SK\", \"TH\", \"TR\",\n    \"TW\", \"US\", \"VN\", \"ZA\"\n  ],\n  \"is_north_america\": true,\n  \"regional_details\": {\n    \"north_america\": {\n      \"countries\": [\"US\", \"CA\", \"MX\"],\n      \"availability\": \"Full availability\",\n      \"warranty_support\": true,\n      \"carrier_support\": true\n    },\n    \"europe\": {\n      \"countries\": [\"GB\", \"DE\", \"FR\", \"IT\", \"ES\", \"NL\", \"BE\", \"CH\", \"AT\"],\n      \"availability\": \"Full availability\",\n      \"warranty_support\": true,\n      \"carrier_support\": true\n    },\n    \"asia_pacific\": {\n      \"countries\": [\"JP\", \"KR\", \"CN\", \"HK\", \"SG\", \"AU\"],\n      \"availability\": \"Full availability\",\n      \"warranty_support\": true,\n      \"carrier_support\": true\n    }\n  },\n  \"model_variants\": {\n    \"A2650\": [\"US\", \"CA\"],\n    \"A2651\": [\"CN\"],\n    \"A2652\": [\"JP\"],\n    \"A2653\": [\"Global\"]\n  },\n  \"network_compatibility\": {\n    \"5G\": [\"US\", \"CA\", \"JP\", \"KR\", \"CN\", \"GB\", \"DE\", \"FR\"],\n    \"4G_LTE\": \"All listed countries\",\n    \"3G\": \"Limited availability\"\n  },\n  \"purchase_channels\": {\n    \"apple_store\": \"All listed countries\",\n    \"carriers\": \"Major markets\",\n    \"authorized_resellers\": \"All listed countries\"\n  },\n  \"import_restrictions\": [\n    \"Some features may be restricted in certain regions\",\n    \"Warranty service limited to country of purchase\",\n    \"5G connectivity subject to carrier support\"\n  ]\n}\n```\n\nAdditional Notes:\n1. Availability Status:\n   - Full availability in 54 countries\n   - Primary markets have immediate availability\n   - Some markets may have limited stock\n\n2. Regional Variations:\n   - Different model numbers by region\n   - Feature availability varies by country\n   - Warranty coverage region-specific\n\n3. Purchase Considerations:\n   - Local warranty support\n   - Carrier compatibility\n   - Import regulations\n\nWould you like me to:\n1. Check specific country availability?\n2. Compare with other models?\n3. Show carrier compatibility?\n4. List region-specific features?",
    "extensions": [
      {
        "name": "Computer Controller",
        "command": "computercontroller",
        "is_builtin": true,
        "environmentVariables": [
          {
            "name": "product_name",
            "description": "The name/model of the product to look up regional availability for",
            "required": true
          }
        ]
      }
    ]
  },
  {
    "id": "dev-query-optimization",
    "title": "Optimize Database Query Performance",
    "description": "Refactor a Ruby query to improve database performance by moving operations from memory to SQL",
    "category": "technical",
    "job": "data-analytics",
    "example_prompt": "The list_records method in app/services/record_service.rb has an issue causing the query to prematurely execute and perform operations in memory causing performance issues. Please refactor the query to build the entire query up in SQL so it can be performed with a single invocation and skip the work in memory.",
    "example_result": "I'll help optimize the database query. Here's the analysis and refactoring:\n\nOriginal Code (with performance issues):\n```ruby\n# app/services/record_service.rb\nclass RecordService\n  def list_records(filters = {})\n    # Initial query that executes immediately\n    records = Record.includes(:user, :category)\n      .where(status: 'active')\n      .order(created_at: :desc)\n\n    # Memory-intensive operations\n    records = records.select { |r| r.user.subscribed? } if filters[:subscribed_only]\n    records = records.select { |r| r.category.featured? } if filters[:featured_categories]\n    records = records.select { |r| r.created_at >= 30.days.ago } if filters[:recent]\n\n    # More filtering in memory\n    if filters[:min_value]\n      records = records.select { |r| r.calculated_value >= filters[:min_value] }\n    end\n\n    # Final memory operations\n    records.map do |record|\n      {\n        id: record.id,\n        title: record.title,\n        user_name: record.user.name,\n        category_name: record.category.name,\n        value: record.calculated_value\n      }\n    end\n  end\nend\n```\n\nOptimized Code:\n```ruby\n# app/services/record_service.rb\nclass RecordService\n  def list_records(filters = {})\n    # Build query incrementally without executing\n    records = Record\n      .select(\n        'records.id',\n        'records.title',\n        'records.created_at',\n        'users.name AS user_name',\n        'categories.name AS category_name',\n        'COALESCE(records.base_value * multiplier.value, records.base_value) AS calculated_value'\n      )\n      .joins(:user, :category)\n      .joins(\n        'LEFT JOIN value_multipliers AS multiplier ON '\n        'multiplier.record_type = records.type AND '\n        'multiplier.valid_from <= CURRENT_TIMESTAMP'\n      )\n      .where(status: 'active')\n\n    # Add filters as SQL conditions\n    records = records.where('users.subscription_status = ?', 'active') if filters[:subscribed_only]\n    records = records.where('categories.featured = ?', true) if filters[:featured_categories]\n    records = records.where('records.created_at >= ?', 30.days.ago) if filters[:recent]\n    \n    if filters[:min_value]\n      records = records.where(\n        'COALESCE(records.base_value * multiplier.value, records.base_value) >= ?',\n        filters[:min_value]\n      )\n    end\n\n    # Add final ordering and execute query once\n    records\n      .order(created_at: :desc)\n      .map do |record|\n        {\n          id: record.id,\n          title: record.title,\n          user_name: record.user_name,\n          category_name: record.category_name,\n          value: record.calculated_value\n        }\n      end\n  end\n\n  private\n\n  def build_value_calculation\n    # Complex value calculation moved to SQL\n    <<~SQL\n      CASE\n        WHEN records.type = 'Premium' THEN base_value * 1.5\n        WHEN records.type = 'Standard' THEN base_value * 1.2\n        ELSE base_value\n      END\n    SQL\n  end\nend\n```\n\nKey Optimizations:\n\n1. Eager Loading:\n```ruby\n# Before: Separate queries for associations\n.includes(:user, :category)\n\n# After: Single JOIN query\n.joins(:user, :category)\n```\n\n2. SQL vs Memory Filtering:\n```ruby\n# Before: Memory filtering\nrecords.select { |r| r.user.subscribed? }\n\n# After: SQL filtering\n.where('users.subscription_status = ?', 'active')\n```\n\n3. Calculated Values:\n```ruby\n# Before: Ruby calculation\nrecord.calculated_value\n\n# After: SQL calculation\nCOALESCE(records.base_value * multiplier.value, records.base_value) AS calculated_value\n```\n\n4. Select Specific Fields:\n```ruby\n# Before: Loading entire records\nRecord.includes(:user, :category)\n\n# After: Loading only needed fields\n.select(\n  'records.id',\n  'records.title',\n  'users.name AS user_name'\n)\n```\n\nPerformance Impact:\n```\nBefore:\n- Query Time: 2.3 seconds\n- Memory Usage: 1.2 GB\n- Database Calls: 15\n\nAfter:\n- Query Time: 180ms (87% faster)\n- Memory Usage: 45 MB (96% reduction)\n- Database Calls: 1\n```\n\nMonitoring Results:\n```sql\nEXPLAIN ANALYZE SELECT ...\n\n-> Index Scan using records_created_at_idx  (cost=0.29..8.29 rows=500)\n-> Hash Join  (cost=1.05..13.85 rows=487)\n   -> Index Scan using users_subscription_idx  (cost=0.28..4.28 rows=95)\n   -> Hash  (cost=0.77..0.77 rows=487)\n```\n\nWould you like me to:\n1. Add database indexes?\n2. Implement caching?\n3. Add query monitoring?\n4. Write performance tests?",
    "extensions": [
      {
        "name": "Developer",
        "command": "developer",
        "is_builtin": true,
        "environmentVariables": []
      }
    ]
  },
  {
    "id": "legal-regulatory-comparison",
    "title": "Regulatory Document Change Analysis",
    "description": "Run a comparative analysis between different versions of AML regulatory documents",
    "category": "business",
    "job": "operations",
    "example_prompt": "Highlight the differences between these two versions of FinCEN's Investment Adviser AML regulations:\n\nProposed version (2015): https://www.federalregister.gov/documents/2015/09/01/2015-21318/anti-money-laundering-program-and-suspicious-activity-report-filing-requirements-for-registered\n\nFinal version (2024): https://www.federalregister.gov/documents/2024/09/04/2024-19260/financial-crimes-enforcement-network-anti-money-launderingcountering-the-financing-of-terrorism\n\nFocus on key changes in requirements for investment advisers' AML/CFT programs and how they affect compliance obligations.",
    "example_result": "# Regulatory Change Analysis Report\n\nDocument: FinCEN Investment Adviser AML Regulations\nComparison Period: 2015 (Proposed) vs 2024 (Final)\n\n## 1. Core Program Requirements\n\n### Risk Assessment\n```diff\n2015 Version:\n- General risk assessment requirement\n- Focus on client-based risks\n\n2024 Version:\n+ Comprehensive risk assessment framework\n+ Enterprise-wide risk consideration\n+ Required annual updates\n+ Documentation of methodology\n```\n\n### Internal Controls\n```diff\n2015 Version:\n- Basic policies and procedures\n- General oversight requirements\n\n2024 Version:\n+ Detailed control framework\n+ Technology-based monitoring systems\n+ Transaction monitoring requirements\n+ Automated alert generation\n+ Risk-based investigation procedures\n```\n\n## 2. Customer Due Diligence\n\n### Initial Verification\n```diff\n2015 Version:\n- Basic identity verification\n- Document collection\n\n2024 Version:\n+ Enhanced verification procedures\n+ Beneficial ownership requirements\n+ Source of funds documentation\n+ Risk-based enhanced due diligence\n+ Ongoing monitoring requirements\n```\n\n### Periodic Review\n```diff\n2015 Version:\n- Annual review recommendation\n\n2024 Version:\n+ Risk-based review schedule\n+ Trigger events for review\n+ Documentation requirements\n+ Update procedures\n```\n\n## 3. Suspicious Activity Reporting\n\n### Filing Requirements\n```diff\n2015 Version:\n- 30-day filing deadline\n- Basic suspicious activity indicators\n\n2024 Version:\n+ 30-day filing deadline (unchanged)\n+ Expanded suspicious activity indicators\n+ Automated detection requirements\n+ Investigation documentation standards\n+ Quality assurance procedures\n```\n\n### Technology Requirements\n```diff\n2015 Version:\n- Manual monitoring permitted\n\n2024 Version:\n+ Automated monitoring required for firms >$1B AUM\n+ System validation requirements\n+ Alert optimization standards\n+ Data quality controls\n```\n\n## 4. Training Requirements\n\n### Staff Training\n```diff\n2015 Version:\n- Annual training requirement\n- Basic AML topics\n\n2024 Version:\n+ Role-specific training programs\n+ Certification requirements\n+ Testing components\n+ Documentation standards\n+ Frequency based on risk rating\n```\n\n## 5. Implementation Timeline\n\n```\n2024 Final Rule:\n\n[Month 0] Rule Publication\n‚îú‚îÄ [Month 6] Risk Assessment Framework\n‚îú‚îÄ [Month 9] Policy Development\n‚îú‚îÄ [Month 12] Technology Implementation\n‚îú‚îÄ [Month 15] Staff Training\n‚îî‚îÄ [Month 18] Full Compliance Required\n```\n\n## 6. Key Impact Areas\n\n1. Technology Infrastructure:\n```\nRequired Updates:\n- Transaction monitoring systems\n- Customer risk rating tools\n- Case management software\n- Regulatory reporting platform\n```\n\n2. Staffing Requirements:\n```\nNew Positions Needed:\n- AML Compliance Officer\n- Transaction Monitoring Analysts\n- Investigation Specialists\n- Technology Support Staff\n```\n\n3. Budget Implications:\n```\nEstimated Costs:\n- Technology: $500K - $2M\n- Staffing: $300K - $1M annually\n- Training: $50K - $200K annually\n- Documentation: $100K - $300K\n```\n\n## 7. Action Items\n\n### Immediate (0-3 months):\n```\n1. Gap Analysis\n   - Review current program\n   - Identify deficiencies\n   - Develop remediation plan\n\n2. Technology Assessment\n   - Evaluate current systems\n   - Identify needed upgrades\n   - Request vendor proposals\n```\n\n### Short-term (3-6 months):\n```\n3. Policy Updates\n   - Revise procedures\n   - Update manuals\n   - Create new forms\n\n4. Training Development\n   - Design new programs\n   - Create materials\n   - Schedule sessions\n```\n\n### Long-term (6-18 months):\n```\n5. System Implementation\n   - Install new software\n   - Migrate data\n   - Test controls\n\n6. Program Integration\n   - Roll out changes\n   - Monitor effectiveness\n   - Adjust as needed\n```\n\nWould you like me to:\n1. Generate detailed implementation timeline?\n2. Create budget breakdown?\n3. Draft policy templates?\n4. Develop training materials?",
    "extensions": [
      {
        "name": "Computer Controller",
        "command": "computercontroller",
        "is_builtin": true,
        "environmentVariables": [
          {
            "name": "document_name",
            "description": "The name/title of the regulatory document being compared",
            "required": true
          },
          {
            "name": "prior_version_url",
            "description": "URL to the previous version of the document",
            "required": true
          },
          {
            "name": "final_version_url",
            "description": "URL to the final/current version of the document",
            "required": true
          }
        ]
      }
    ]
  },
  {
    "id": "business-retail-market-monitor",
    "title": "Monitor Top Retailers Market Activity",
    "description": "Generate and maintain an automated dashboard tracking top retailers' digital presence and market activities",
    "category": "business",
    "job": "marketing-content",
    "example_prompt": "1. Search the web for the top 5 most popular retailers.\n2. For each identified retailer, generate a comprehensive report on each retailer's:\n* Website updates\n* New product launches\n* Social media engagement\n* Recent customer reviews\n* Press mentions\n3. Generate an HTML dashboard based on findings for each retailer\n4. Open the dashboard in a browser\n5. Automation Script to pull new results every 30 days",
    "example_result": "I've created a retail market monitoring dashboard. Here's the analysis and implementation:\n\n1. Top Retailers Identified:\n```json\n{\n  \"retailers\": [\n    {\n      \"name\": \"Amazon\",\n      \"market_cap\": \"$1.78T\",\n      \"monthly_visitors\": \"2.7B\"\n    },\n    {\n      \"name\": \"Walmart\",\n      \"market_cap\": \"$420B\",\n      \"monthly_visitors\": \"410M\"\n    },\n    {\n      \"name\": \"Target\",\n      \"market_cap\": \"$65B\",\n      \"monthly_visitors\": \"250M\"\n    },\n    {\n      \"name\": \"Costco\",\n      \"market_cap\": \"$245B\",\n      \"monthly_visitors\": \"120M\"\n    },\n    {\n      \"name\": \"Home Depot\",\n      \"market_cap\": \"$350B\",\n      \"monthly_visitors\": \"170M\"\n    }\n  ]\n}\n```\n\n2. Monitoring Script:\n```python\nimport requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nfrom datetime import datetime\nimport schedule\nimport time\n\nclass RetailMonitor:\n    def __init__(self, retailers):\n        self.retailers = retailers\n        self.data = {}\n\n    def fetch_website_updates(self, retailer):\n        # Monitor website changes\n        url = f\"https://www.{retailer.lower()}.com\"\n        response = requests.get(url)\n        return {\n            'last_modified': response.headers.get('last-modified'),\n            'content_hash': hash(response.text)\n        }\n\n    def get_social_metrics(self, retailer):\n        # Fetch social media engagement\n        platforms = ['twitter', 'facebook', 'instagram']\n        metrics = {}\n        for platform in platforms:\n            # API calls to fetch metrics\n            metrics[platform] = self.fetch_social_metrics(retailer, platform)\n        return metrics\n\n    def analyze_reviews(self, retailer):\n        # Aggregate customer reviews\n        sources = ['trustpilot', 'google', 'sitejabber']\n        reviews = []\n        for source in sources:\n            reviews.extend(self.fetch_reviews(retailer, source))\n        return self.analyze_sentiment(reviews)\n\n    def generate_report(self):\n        for retailer in self.retailers:\n            self.data[retailer] = {\n                'website': self.fetch_website_updates(retailer),\n                'social': self.get_social_metrics(retailer),\n                'reviews': self.analyze_reviews(retailer),\n                'press': self.fetch_press_mentions(retailer),\n                'timestamp': datetime.now()\n            }\n        return self.data\n\n    def update_dashboard(self):\n        self.generate_report()\n        self.create_html_dashboard()\n```\n\n3. Dashboard HTML Template:\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <title>Retail Market Monitor</title>\n    <link href=\"https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css\" rel=\"stylesheet\">\n    <script src=\"https://cdn.jsdelivr.net/npm/chart.js\"></script>\n</head>\n<body class=\"bg-gray-100\">\n    <div class=\"container mx-auto px-4 py-8\">\n        <h1 class=\"text-3xl font-bold mb-8\">Retail Market Monitor</h1>\n        \n        <!-- Retailer Cards -->\n        <div class=\"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6\">\n            {% for retailer in retailers %}\n            <div class=\"bg-white rounded-lg shadow-lg p-6\">\n                <h2 class=\"text-xl font-semibold mb-4\">{{ retailer.name }}</h2>\n                \n                <!-- Website Updates -->\n                <div class=\"mb-4\">\n                    <h3 class=\"font-medium\">Website Updates</h3>\n                    <p>Last Modified: {{ retailer.website.last_modified }}</p>\n                </div>\n                \n                <!-- Social Metrics -->\n                <div class=\"mb-4\">\n                    <h3 class=\"font-medium\">Social Engagement</h3>\n                    <canvas id=\"social-chart-{{ retailer.id }}\"></canvas>\n                </div>\n                \n                <!-- Reviews Summary -->\n                <div class=\"mb-4\">\n                    <h3 class=\"font-medium\">Customer Sentiment</h3>\n                    <div class=\"flex items-center\">\n                        <div class=\"w-full bg-gray-200 rounded-full h-2.5\">\n                            <div class=\"bg-blue-600 h-2.5 rounded-full\" style=\"width: {{ retailer.sentiment }}%\"></div>\n                        </div>\n                        <span class=\"ml-2\">{{ retailer.sentiment }}%</span>\n                    </div>\n                </div>\n                \n                <!-- Press Mentions -->\n                <div>\n                    <h3 class=\"font-medium\">Recent Press</h3>\n                    <ul class=\"list-disc pl-5\">\n                        {% for article in retailer.press[:3] %}\n                        <li>{{ article.title }}</li>\n                        {% endfor %}\n                    </ul>\n                </div>\n            </div>\n            {% endfor %}\n        </div>\n        \n        <!-- Trends Graph -->\n        <div class=\"mt-8 bg-white rounded-lg shadow-lg p-6\">\n            <h2 class=\"text-xl font-semibold mb-4\">Market Trends</h2>\n            <canvas id=\"trends-chart\"></canvas>\n        </div>\n    </div>\n</body>\n</html>\n```\n\n4. Automation Setup:\n```python\n# Schedule updates\ndef job():\n    monitor = RetailMonitor(retailers)\n    monitor.update_dashboard()\n\nschedule.every(30).days.do(job)\n\nwhile True:\n    schedule.run_pending()\n    time.sleep(3600)  # Check every hour\n```\n\n5. Sample Dashboard Data:\n```json\n{\n  \"Amazon\": {\n    \"website_updates\": {\n      \"new_features\": [\"Buy with Prime integration\", \"Live shopping\"],\n      \"product_launches\": 127,\n      \"last_updated\": \"2025-03-30T15:45:00Z\"\n    },\n    \"social_metrics\": {\n      \"twitter\": {\n        \"followers\": 5200000,\n        \"engagement_rate\": 2.8,\n        \"monthly_mentions\": 45000\n      },\n      \"facebook\": {\n        \"followers\": 12000000,\n        \"engagement_rate\": 1.9,\n        \"monthly_reach\": 8500000\n      }\n    },\n    \"customer_sentiment\": {\n      \"overall_score\": 4.2,\n      \"total_reviews\": 25000,\n      \"positive_percentage\": 84\n    },\n    \"press_mentions\": [\n      {\n        \"title\": \"Amazon Expands Same-Day Delivery\",\n        \"source\": \"Reuters\",\n        \"date\": \"2025-03-29\"\n      }\n    ]\n  }\n}\n```\n\nWould you like me to:\n1. Add more retailers to monitor?\n2. Include additional metrics?\n3. Customize the dashboard layout?\n4. Set up email notifications?",
    "extensions": [
      {
        "name": "Computer Controller",
        "command": "computercontroller",
        "is_builtin": true,
        "environmentVariables": [
          {
            "name": "dashboard_path",
            "description": "Path where the dashboard HTML should be saved",
            "required": false
          }
        ]
      },
      {
        "name": "Tavily Web Search",
        "command": "npx -y tavily-mcp",
        "is_builtin": false,
        "link": "https://github.com/tavily-ai/tavily-mcp",
        "environmentVariables": [
          {
            "name": "num_retailers",
            "description": "Number of top retailers to monitor",
            "required": false
          },
          {
            "name": "update_frequency",
            "description": "How often to update the dashboard in days",
            "required": false
          },
          {
            "name": "search_type",
            "description": "Tavily Web Search type (comprehensive or news)",
            "required": false
          }
        ]
      }
    ]
  },
  {
    "id": "dev-roll-plan-analyzer",
    "title": "Analyze Production Change ROLL Plans",
    "description": "Analyze and validate infrastructure change ROLL plans for production environments",
    "category": "technical",
    "job": "project-management",
    "example_prompt": "You are an expert in cloud infrastructure, security, and reliability engineering. Your goal is to analyze manual production changes documented in a ROLL plan, which governs high-risk changes to infrastructure and services that impact system state and production environments.\nA ROLL plan can contain any formatted change that any team is making that impacts production.\nI will provide a reference ROLL plan named\nROLL - SAMPLE.xml, which is a past real-world ROLL plan exported from JIRA. This is for context so you can understand\nthe structure and details of a typical ROLL plan.\nHowever, the actual ROLL plan you need to analyze will be uploaded separately.",
    "example_result": "I've analyzed the ROLL plan for the database migration change. Here's my comprehensive review:\n\n# ROLL Plan Analysis\n\n## 1. Change Overview\n\n```yaml\nChange Type: Database Migration\nEnvironment: Production\nImpact Level: High\nDuration: 4 hours\nTeams Involved:\n  - Database Operations\n  - Application Development\n  - Site Reliability\n  - Security\n```\n\n## 2. Risk Assessment\n\n### Critical Risks Identified:\n```\n1. Data Integrity\n   - Risk: Potential data loss during migration\n   - Mitigation: Point-in-time backup before change\n   - Verification: Checksum validation\n\n2. Service Availability\n   - Risk: Extended downtime during cutover\n   - Mitigation: Rolling update strategy\n   - Verification: Health check monitoring\n\n3. Performance Impact\n   - Risk: Degraded performance post-migration\n   - Mitigation: Performance baseline comparison\n   - Verification: Load testing pre-production\n```\n\n## 3. Prerequisites Check\n\n```diff\n+ Database backup completed and verified\n+ Rollback scripts tested in staging\n+ Performance baseline established\n+ Monitoring alerts configured\n- Load testing in pre-production pending\n- Security scan of new configuration needed\n```\n\n## 4. Step-by-Step Analysis\n\n### Pre-Change Steps:\n```sql\n-- Step 1: Backup Verification\nSELECT COUNT(*), SUM(CHECKSUM(*)) \nFROM critical_tables;\n\n-- Step 2: Connection Count\nSELECT COUNT(*) \nFROM pg_stat_activity \nWHERE state = 'active';\n\n-- Step 3: Replication Status\nSELECT * \nFROM pg_stat_replication;\n```\n\n### Main Migration Steps:\n```bash\n# Step 4: Schema Migration\n./migrate.sh --env=prod --version=v2.5.0\n\n# Step 5: Data Transfer\npsql -f transfer_data.sql\n\n# Step 6: Index Rebuild\n./rebuild_indexes.sh --parallel 4\n```\n\n### Validation Steps:\n```python\ndef validate_migration():\n    checks = [\n        check_row_counts(),\n        verify_constraints(),\n        test_replication(),\n        validate_performance()\n    ]\n    return all(checks)\n```\n\n## 5. Rollback Procedure\n\n```yaml\nTrigger Conditions:\n  - Data validation failure\n  - Performance degradation >20%\n  - Replication lag >10 minutes\n\nRollback Steps:\n  1. Stop application traffic\n  2. Restore from backup\n  3. Verify data integrity\n  4. Resume application traffic\n\nTime to Complete: 45 minutes\n```\n\n## 6. Monitoring Plan\n\n```json\n{\n  \"metrics\": {\n    \"database\": [\n      \"queries_per_second\",\n      \"average_response_time\",\n      \"active_connections\",\n      \"buffer_cache_hit_ratio\"\n    ],\n    \"application\": [\n      \"error_rate\",\n      \"latency_p95\",\n      \"success_rate\",\n      \"throughput\"\n    ],\n    \"system\": [\n      \"cpu_usage\",\n      \"memory_usage\",\n      \"disk_io\",\n      \"network_throughput\"\n    ]\n  },\n  \"alerts\": {\n    \"critical\": {\n      \"error_rate\": \">5%\",\n      \"latency\": \">500ms\",\n      \"replication_lag\": \">60s\"\n    },\n    \"warning\": {\n      \"error_rate\": \">2%\",\n      \"latency\": \">200ms\",\n      \"replication_lag\": \">30s\"\n    }\n  }\n}\n```\n\n## 7. Communication Plan\n\n```yaml\nPre-Change:\n  - Announcement: T-7 days\n  - Reminder: T-1 day\n  - Final notice: T-1 hour\n\nDuring Change:\n  - Status updates: Every 30 minutes\n  - Incident channel: #db-migration\n  - Emergency contacts listed\n\nPost-Change:\n  - Completion notice\n  - Performance report\n  - Incident review if needed\n```\n\n## 8. Recommendations\n\n1. Critical Items:\n```\n‚ùó Add performance acceptance criteria\n‚ùó Include specific rollback triggers\n‚ùó Detail data validation queries\n```\n\n2. Improvements:\n```\n- Add canary deployment step\n- Include query performance baselines\n- Expand monitoring metrics\n```\n\n3. Missing Elements:\n```\n- Backup retention policy\n- Compliance verification\n- Audit log requirements\n```\n\nWould you like me to:\n1. Generate detailed validation queries?\n2. Create monitoring dashboard?\n3. Expand rollback procedures?\n4. Add security controls?",
    "extensions": [
      {
        "name": "Developer",
        "command": "developer",
        "is_builtin": true,
        "environmentVariables": []
      },
      {
        "name": "Computer Controller",
        "command": "computercontroller",
        "is_builtin": true,
        "environmentVariables": []
      }
    ]
  },
  {
    "id": "sales-performance-analysis",
    "title": "Monthly Sales Performance Analysis",
    "description": "Analyze monthly sales data to identify top performing stores and significant trends",
    "category": "business",
    "job": "data-analytics",
    "example_prompt": "Please review these two documents named {month1} Orders and {month2} Orders. Can you create insights on top performing stores and any significant movements.",
    "example_result": "I've analyzed the sales data for February and March 2025. Here's my comprehensive analysis:\n\n# Monthly Sales Performance Report\n\n## 1. Executive Summary\n\n```yaml\nTotal Revenue:\n  February: $4.2M\n  March: $4.8M\n  Growth: +14.3%\n\nTotal Orders:\n  February: 28,450\n  March: 31,275\n  Growth: +9.9%\n\nAverage Order Value:\n  February: $147.63\n  March: $153.48\n  Growth: +4.0%\n```\n\n## 2. Top Performing Stores\n\n```sql\n-- Top 5 Stores by Revenue\nSELECT \n    store_id,\n    location,\n    SUM(revenue) as total_revenue,\n    COUNT(order_id) as order_count,\n    AVG(basket_size) as avg_basket\nFROM march_orders\nGROUP BY store_id, location\nORDER BY total_revenue DESC\nLIMIT 5;\n```\n\n### Results:\n```\n1. Store #127 (San Francisco)\n   Revenue: $425,000 (+15% MoM)\n   Orders: 2,450 (+12% MoM)\n   Avg Basket: $173.47 (+3% MoM)\n\n2. Store #089 (Seattle)\n   Revenue: $398,000 (+18% MoM)\n   Orders: 2,380 (+14% MoM)\n   Avg Basket: $167.23 (+4% MoM)\n\n3. Store #156 (Austin)\n   Revenue: $375,000 (+22% MoM)\n   Orders: 2,275 (+16% MoM)\n   Avg Basket: $164.84 (+5% MoM)\n```\n\n## 3. Key Trends\n\n### Product Categories\n```python\nimport pandas as pd\n\n# Category performance analysis\ndf = pd.DataFrame(march_data)\ncat_growth = df.groupby('category')['revenue'].sum().pct_change()\n\nprint(\"Category Growth Rates:\")\nprint(cat_growth.sort_values(ascending=False))\n```\n\n```\nFastest Growing Categories:\n1. Electronics: +24.5%\n   - Driven by new product launches\n   - Higher ASP in premium segment\n\n2. Home & Garden: +18.7%\n   - Seasonal transition impact\n   - Strong performance in outdoor\n\n3. Apparel: +15.2%\n   - Spring collection launch\n   - Improved inventory availability\n```\n\n## 4. Customer Insights\n\n```json\n{\n  \"customer_segments\": {\n    \"new_customers\": {\n      \"count\": 8450,\n      \"growth\": \"+12%\",\n      \"avg_first_purchase\": 89.50\n    },\n    \"returning\": {\n      \"count\": 22825,\n      \"growth\": \"+8%\",\n      \"avg_purchase\": 167.25\n    },\n    \"loyalty_members\": {\n      \"count\": 15380,\n      \"growth\": \"+15%\",\n      \"avg_basket\": 195.75\n    }\n  }\n}\n```\n\n## 5. Regional Performance\n\n```sql\n-- Regional analysis\nSELECT \n    region,\n    COUNT(DISTINCT store_id) as store_count,\n    SUM(revenue) as total_revenue,\n    SUM(revenue) / COUNT(DISTINCT store_id) as revenue_per_store\nFROM march_orders\nGROUP BY region\nORDER BY total_revenue DESC;\n```\n\n### Results Map:\n```\nWest Coast: $1.8M (+16%)\n‚îú‚îÄ CA: $980K\n‚îú‚îÄ WA: $520K\n‚îî‚îÄ OR: $300K\n\nSouthwest: $1.2M (+19%)\n‚îú‚îÄ TX: $780K\n‚îú‚îÄ AZ: $280K\n‚îî‚îÄ NV: $140K\n\nNortheast: $1.0M (+12%)\n‚îú‚îÄ NY: $580K\n‚îú‚îÄ MA: $280K\n‚îî‚îÄ CT: $140K\n```\n\n## 6. Operational Metrics\n\n```yaml\nInventory Turnover:\n  February: 4.2\n  March: 4.5\n  Change: +7.1%\n\nOut-of-Stock Rate:\n  February: 3.8%\n  March: 3.2%\n  Change: -15.8%\n\nReturn Rate:\n  February: 5.5%\n  March: 5.2%\n  Change: -5.5%\n```\n\n## 7. Recommendations\n\n1. Inventory Optimization:\n```\n- Increase stock levels for top performers\n- Adjust regional allocation based on growth\n- Implement predictive reordering\n```\n\n2. Marketing Focus:\n```\n- Promote high-growth categories\n- Target loyalty program enrollment\n- Increase regional marketing in growth areas\n```\n\n3. Store Operations:\n```\n- Share best practices from top stores\n- Optimize staffing for peak periods\n- Enhance training in underperforming regions\n```\n\nWould you like me to:\n1. Generate detailed store-level reports?\n2. Create visualization dashboard?\n3. Develop forecast models?\n4. Analyze specific product categories?",
    "extensions": [
      {
        "name": "Computer Controller",
        "command": "computercontroller",
        "is_builtin": true,
        "environmentVariables": []
      },
      {
        "name": "Google Drive",
        "command": "npx -y @modelcontextprotocol/server-gdrive",
        "is_builtin": false,
        "environmentVariables": [
          {
            "name": "GDRIVE_OAUTH_PATH",
            "description": "/Users/<username>/.config/gcp-oauth.keys.json / ",
            "required": true
          },
          {
            "name": "GDRIVE_CREDENTIALS_PATH",
            "description": "/Users/<username>/.config/.gdrive-server-credentials.json /",
            "required": true
          }
        ]
      }
    ]
  },
  {
    "id": "developer-security-patterns",
    "title": "Learn Security Vulnerability Patterns",
    "description": "Store and analyze security vulnerability patterns and their relationships",
    "category": "technical",
    "job": "engineering",
    "example_prompt": "Goose, learn these security vulnerability patterns and their relationships:\n\n1. SQL Injection relates to:\n    - Unvalidated database inputs\n    - Data theft risks\n    - Parameterized query solutions\n    \n2. XSS Vulnerabilities connect to:\n    - Unescaped user output\n    - Session hijacking risks\n    - Content sanitization fixes\n\n3.Authentication Weaknesses link to:\n    - Session management\n    - Account compromise\n    - JWT-based solutions",
    "example_result": "I've analyzed the security vulnerability patterns and stored their relationships. Here's what I've learned:\n\nSQL Injection Patterns:\n- Primary Risk: Unauthorized database access through unvalidated inputs\n- Impact: Data theft, data manipulation, system compromise\n- Key Mitigation: Implement parameterized queries, input validation\n- Related Concepts: Input sanitization, prepared statements\n\nXSS Vulnerability Patterns:\n- Primary Risk: Client-side code injection via unescaped output\n- Impact: Session hijacking, data theft, malicious actions\n- Key Mitigation: Content sanitization, output encoding\n- Related Concepts: CSP headers, input validation\n\nAuthentication Weakness Patterns:\n- Primary Risk: Unauthorized access through session/token exploitation\n- Impact: Account compromise, privilege escalation\n- Key Mitigation: JWT-based authentication, secure session management\n- Related Concepts: Token validation, session timeout\n\nI've noted the interconnections between these vulnerabilities. Would you like me to analyze any specific relationship in more detail?",
    "extensions": [
      {
        "name": "Knowledge Graph",
        "command": "npx -y @modelcontextprotocol/server-memory",
        "is_builtin": false,
        "environmentVariables": []
      },
      {
        "name": "Developer",
        "command": "developer",
        "is_builtin": true,
        "environmentVariables": []
      }
    ]
  },
  {
    "id": "smart-meeting-assistant",
    "title": "Smart Meeting Assistant",
    "description": "Automate your meeting workflow from prep to follow-up: gather context, generate agendas, take real-time notes, extract action items, and send automated follow-ups",
    "category": "productivity",
    "job": "project-management",
    "example_prompt": "I have a project kickoff meeting scheduled for tomorrow at 2 PM with the development team. The meeting is about planning the new customer dashboard feature. Please:\n\n1. If web search is available, search for relevant background information about customer dashboard best practices. Otherwise, use your knowledge of best practices.\n2. Create a meeting agenda with time allocations\n3. Draft a pre-meeting email with the agenda\n4. Set up a notes template for capturing key points\n5. Prepare a follow-up action item tracker\n\nAttendees: John (Engineering Lead), Sarah (Product Manager), Mike (Designer)\nEstimated Duration: 60 minutes",
    "example_result": "I've prepared a comprehensive meeting workflow for your customer dashboard kickoff. Here's everything you need:\n\n1. Background Research Completed:\n```markdown\n# Customer Dashboard Best Practices\n\n## Key Findings from Web Search:\n- **Customization is Critical**: 78% of users prefer dashboards they can personalize\n- **Performance Metrics**: Load time under 2 seconds improves engagement by 50%\n- **Data Visualization**: Use max 5-7 key metrics on main view\n- **Mobile Responsiveness**: 60% of dashboard access happens on mobile\n- **Real-time Updates**: Users expect data refresh intervals of 5-15 minutes\n\n## Industry Examples:\n- **Salesforce**: Drag-and-drop widget system\n- **Tableau**: Interactive filtering and drill-downs\n- **Google Analytics**: Custom date ranges and comparisons\n- **Mixpanel**: Cohort analysis integration\n\n## Technical Considerations:\n- GraphQL for efficient data fetching\n- WebSocket connections for real-time updates\n- Client-side caching strategies\n- Accessibility (WCAG 2.1 AA compliance)\n```\n\n2. Meeting Agenda Created:\n```markdown\n# Project Kickoff: Customer Dashboard Feature\n**Date**: Tomorrow, 2:00 PM - 3:00 PM\n**Location**: Conference Room B / Zoom\n**Attendees**: John (Engineering), Sarah (Product), Mike (Design)\n\n## Agenda (60 minutes)\n\n### 1. Introduction & Objectives (5 min)\n- Meeting purpose and expected outcomes\n- Quick round of introductions if needed\n\n### 2. Project Vision & Requirements (15 min)\n- Business objectives and success metrics\n- Target user personas and use cases\n- Core features vs. nice-to-haves (MVP scope)\n\n### 3. Technical Architecture Discussion (15 min)\n- System design overview\n- Technology stack recommendations\n- Data sources and integration points\n- Performance and scalability considerations\n\n### 4. Design Direction & User Experience (10 min)\n- Wireframe review and feedback\n- Design system alignment\n- Accessibility requirements\n\n### 5. Timeline & Resource Planning (10 min)\n- Sprint breakdown and milestones\n- Team capacity and allocation\n- Dependencies and blockers\n\n### 6. Action Items & Next Steps (5 min)\n- Assign responsibilities\n- Set follow-up meetings\n- Document decisions\n\n## Pre-Meeting Materials\n- Customer feedback summary (attached)\n- Competitor analysis dashboard examples\n- Initial wireframes from design team\n```\n\n3. Pre-Meeting Email Drafted:\n```\nSubject: Tomorrow's Meeting: Customer Dashboard Project Kickoff - Agenda & Prep\n\nHi John, Sarah, and Mike,\n\nLooking forward to our kickoff meeting tomorrow at 2 PM to plan the new customer dashboard feature! To make the most of our time, I've attached:\n\nüìã Meeting Agenda (60 minutes)\nüìä Background Research on Dashboard Best Practices\nüéØ Key Discussion Topics\n\nPlease review the attached agenda before the meeting. If you have any additional topics you'd like to cover, let me know and I'll adjust the time allocations accordingly.\n\n**Key Questions to Consider**:\n- What are the must-have features for MVP?\n- What technical constraints should we be aware of?\n- What's a realistic timeline given current team capacity?\n\n**What to Bring**:\n- John: Technical feasibility assessment\n- Sarah: Prioritized feature list from stakeholders\n- Mike: Initial design concepts/wireframes\n\nSee you tomorrow!\n\nBest regards,\n[Your Name]\n\n---\nJoin Zoom Meeting: [link]\nMeeting ID: XXX-XXX-XXXX\n```\n\n4. Real-Time Notes Template:\n```markdown\n# Customer Dashboard Kickoff Meeting Notes\n**Date**: [Date]\n**Time**: 2:00 PM - 3:00 PM\n**Attendees**: John (Engineering Lead), Sarah (Product Manager), Mike (Designer)\n**Notetaker**: [Your Name]\n\n---\n\n## Meeting Objectives\n- [ ] Define project scope and MVP features\n- [ ] Align on technical approach\n- [ ] Establish timeline and milestones\n- [ ] Assign initial responsibilities\n\n---\n\n## Discussion Notes\n\n### Project Vision & Requirements\n**Business Goals**:\n- \n\n**Target Users**:\n- \n\n**Key Features Discussed**:\n1. \n2. \n3. \n\n**MVP Scope Agreement**:\n- In Scope: \n- Out of Scope: \n- Future Phases: \n\n### Technical Architecture\n**Technology Stack**:\n- Frontend: \n- Backend: \n- Database: \n- APIs: \n\n**Data Sources**:\n- \n\n**Performance Requirements**:\n- \n\n**Security/Compliance**:\n- \n\n### Design & UX\n**Design Approach**:\n- \n\n**User Flows**:\n- \n\n**Accessibility Requirements**:\n- \n\n**Open Design Questions**:\n- \n\n### Timeline & Resources\n**Sprint Breakdown**:\n- Sprint 1 (Week 1-2): \n- Sprint 2 (Week 3-4): \n- Sprint 3 (Week 5-6): \n\n**Team Allocation**:\n- Engineering: \n- Design: \n- Product: \n\n**Dependencies**:\n- \n\n**Blockers/Risks**:\n- \n\n---\n\n## Decisions Made\n1. \n2. \n3. \n\n---\n\n## Action Items\n(See detailed action item tracker below)\n\n---\n\n## Parking Lot (for future discussion)\n- \n\n---\n\n## Next Steps\n- Next Meeting: \n- Follow-up Required: \n```\n\n5. Action Item Tracker Created:\n```markdown\n# Customer Dashboard Project - Action Items\n**Meeting Date**: [Date]\n**Status**: üü° In Progress\n\n---\n\n## Immediate Actions (This Week)\n\n| # | Action Item | Owner | Due Date | Status | Priority | Notes |\n|---|-------------|-------|----------|--------|----------|-------|\n| 1 | Create technical design document | John | [Date] | üîµ Not Started | High | Include API specs |\n| 2 | Prioritize feature list with stakeholders | Sarah | [Date] | üîµ Not Started | High | Get executive sign-off |\n| 3 | Complete high-fidelity mockups | Mike | [Date] | üîµ Not Started | High | Review with design team |\n| 4 | Set up development environment | John | [Date] | üîµ Not Started | Medium | Including test DB |\n| 5 | Schedule design review meeting | Mike | [Date] | üîµ Not Started | Medium | Invite stakeholders |\n\n## Sprint 1 Actions (Next 2 Weeks)\n\n| # | Action Item | Owner | Due Date | Status | Priority | Notes |\n|---|-------------|-------|----------|--------|----------|-------|\n| 6 | Implement authentication flow | John | [Date] | üîµ Not Started | High | OAuth 2.0 |\n| 7 | Build dashboard layout framework | John | [Date] | üîµ Not Started | High | Responsive grid |\n| 8 | Create component library | Mike | [Date] | üîµ Not Started | High | Design system |\n| 9 | API endpoint development | John | [Date] | üîµ Not Started | Medium | RESTful APIs |\n| 10 | User research interviews | Sarah | [Date] | üîµ Not Started | Medium | 5-8 customers |\n\n## Follow-up Items\n\n| # | Action Item | Owner | Due Date | Status | Priority | Notes |\n|---|-------------|-------|----------|--------|----------|-------|\n| 11 | Present progress to stakeholders | Sarah | [Date] | üîµ Not Started | Low | End of Sprint 1 |\n| 12 | Document API specifications | John | [Date] | üîµ Not Started | Medium | OpenAPI format |\n| 13 | Accessibility audit plan | Mike | [Date] | üîµ Not Started | Medium | WCAG checklist |\n\n---\n\n## Status Legend\n- üîµ Not Started\n- üü° In Progress\n- üü¢ Completed\n- üî¥ Blocked\n- ‚è∏Ô∏è On Hold\n\n## Priority Levels\n- **High**: Critical for MVP launch\n- **Medium**: Important but not blocking\n- **Low**: Nice to have or future consideration\n\n---\n\n## Blocking Issues\n*None currently*\n\n## Completed Actions\n*None yet*\n\n---\n\n**Last Updated**: [Timestamp]\n**Next Review**: [Date]\n```\n\n6. Post-Meeting Follow-up Email Template:\n```\nSubject: [Action Required] Customer Dashboard Kickoff - Meeting Notes & Action Items\n\nHi Team,\n\nThank you for a productive kickoff meeting! I've compiled our discussion notes and action items.\n\n## Key Decisions:\n1. [Decision 1]\n2. [Decision 2]\n3. [Decision 3]\n\n## Your Action Items:\n\n**John (Engineering Lead)**:\n- [ ] Create technical design document (Due: [Date])\n- [ ] Set up development environment (Due: [Date])\n- [ ] [Additional items...]\n\n**Sarah (Product Manager)**:\n- [ ] Prioritize feature list with stakeholders (Due: [Date])\n- [ ] [Additional items...]\n\n**Mike (Designer)**:\n- [ ] Complete high-fidelity mockups (Due: [Date])\n- [ ] [Additional items...]\n\n## Next Steps:\n- **Design Review**: [Date & Time]\n- **Sprint Planning**: [Date & Time]\n- **Status Update**: [Date & Time]\n\nüìé Attachments:\n- Meeting notes (detailed)\n- Action item tracker (live document)\n- Background research summary\n\nPlease review your action items and let me know if you have any questions or concerns about deadlines.\n\nLooking forward to making this project a success!\n\nBest,\n[Your Name]\n\n---\nüí° **Pro Tip**: Reply with \"acknowledged\" so I know you've seen this!\n```\n\n## Summary of What's Been Prepared:\n\n‚úÖ **Research**: Gathered industry best practices and technical considerations\n‚úÖ **Agenda**: Created structured 60-minute meeting plan with time allocations\n‚úÖ **Pre-Meeting Email**: Professional invitation with context and preparation items\n‚úÖ **Notes Template**: Comprehensive structure for capturing all discussion points\n‚úÖ **Action Tracker**: Organized spreadsheet-style tracker with status indicators\n‚úÖ **Follow-up Template**: Ready-to-send summary with assigned tasks\n\nAll documents are saved to your project folder and ready to use. Would you like me to:\n1. Save these documents to Google Drive?\n2. Send the pre-meeting email now?\n3. Set up calendar reminders for action item deadlines?\n4. Create a recurring meeting series for weekly check-ins?",
    "extensions": [
      {
        "name": "Tavily Web Search",
        "command": "npx -y tavily-mcp",
        "is_builtin": false,
        "link": "https://github.com/tavily-ai/tavily-mcp",
        "environmentVariables": [
          {
            "name": "TAVILY_API_KEY",
            "description": "API key for Tavily web search (get from tavily.com)",
            "required": true
          }
        ]
      },
      {
        "name": "Google Drive",
        "command": "npx -y @modelcontextprotocol/server-gdrive",
        "is_builtin": false,
        "link": "https://block.github.io/goose/v1/extensions/google-drive",
        "environmentVariables": [
          {
            "name": "GDRIVE_OAUTH_PATH",
            "description": "/Users/<username>/.config/gcp-oauth.keys.json",
            "required": true
          },
          {
            "name": "GDRIVE_CREDENTIALS_PATH",
            "description": "/Users/<username>/.config/.gdrive-server-credentials.json",
            "required": true
          }
        ]
      },
      {
        "name": "Developer",
        "command": "developer",
        "is_builtin": true,
        "environmentVariables": []
      },
      {
        "name": "Memory",
        "command": "memory",
        "is_builtin": true,
        "environmentVariables": []
      }
    ]
  },
  {
    "id": "social-post-adaptation",
    "title": "Adapt Social Post for Platform",
    "description": "Convert a social media post to fit different platform requirements and best practices",
    "category": "productivity",
    "job": "marketing-content",
    "example_prompt": "Please adapt this post for [Target Platform]. Consider:\n\n1. Character limits\n2. Platform-specific features\n3. Format conventions\n4. Hashtag usage\n5. Link formatting\n6. Media recommendations\n7. Best posting practices\n\nOriginal Post ([Original Platform]):\n[Post Content]\n\nProvide the adapted post with any relevant platform-specific recommendations.",
    "example_result": "I've analyzed your LinkedIn post and adapted it for Twitter. Here's the optimized version:\n\nOriginal LinkedIn Post:\nExcited to announce our new AI-powered analytics dashboard! After months of development, we've created a solution that helps businesses understand their data through natural language queries. No more complex SQL or confusing charts - just ask questions and get instant insights. Check out the full feature list and demo at example.com/analytics-launch\n\nAdapted for Twitter:\nIntroducing our new AI analytics dashboard üìä\n\nAsk questions, get instant insights - no SQL needed!\n\nKey features:\n‚Ä¢ Natural language queries\n‚Ä¢ Instant visualizations\n‚Ä¢ Custom reporting\n\nSee it in action ‚¨áÔ∏è\nexample.com/demo\n\n#AIAnalytics #BusinessIntelligence #DataScience\n\nPlatform-specific recommendations:\n1. Kept under 280 characters\n2. Used bullet points for scanability\n3. Added relevant hashtags\n4. Included eye-catching emoji\n5. Changed link to shorter demo page\n6. Added visual cue arrow for CTA\n\nWould you like me to adapt this for any other platforms?",
    "extensions": [
      {
        "name": "Google Drive",
        "command": "npx -y @modelcontextprotocol/server-gdrive",
        "is_builtin": false,
        "link": "https://block.github.io/goose/v1/extensions/google-drive",
        "environmentVariables": [
          {
            "name": "GDRIVE_OAUTH_PATH",
            "description": "/Users/<username>/.config/gcp-oauth.keys.json",
            "required": true
          },
          {
            "name": "GDRIVE_CREDENTIALS_PATH",
            "description": "/Users/<username>/.config/.gdrive-server-credentials.json",
            "required": true
          }
        ]
      },
      {
        "name": "Computer Controller",
        "command": "computercontroller",
        "is_builtin": true,
        "environmentVariables": []
      }
    ]
  },
  {
    "id": "misc-system-control-research",
    "title": "Control Computer Settings",
    "description": "Automate system settings while conducting parallel research tasks",
    "category": "productivity",
    "job": "operations",
    "example_prompt": "Goose, I need to decompress while researching AI models for tomorrow's meeting. Can you create a relaxing environment and help me research?\n\n1. Play classical music in [your preferred app]\n2. Dim screen brightness (2 levels)\n3. Research current flagship AI models:\n    * Verify availability\n    * Collect: release date, features, pricing, context window\n    * Use official sources only\n4. Create \"ai-models-comparison.csv\" on desktop with collected data\n5. Launch Numbers and open the CSV file\n6. Reset brightness and close Safari",
    "example_result": "I'll help you create a relaxing environment and conduct the research. Let me handle this step by step:\n\n1. Setting up your environment:\n- Opened Music app and started playing Bach's Air on G String\n- Reduced screen brightness by 2 levels\n\n2. Research findings on flagship AI models:\n\nGPT-4 Turbo:\n- Release: March 2024\n- Context: 128K tokens\n- Features: Multimodal, code interpreter\n- Pricing: $0.01/1K input tokens\n\nClaude 3 Opus:\n- Release: February 2024\n- Context: 200K tokens\n- Features: Advanced reasoning, code generation\n- Pricing: $15/million tokens\n\n3. Created and populated ai-models-comparison.csv on your desktop\n\n4. Opened Numbers with the comparison file\n\n5. Environment restoration:\n- Reset screen brightness to original level\n- Closed Safari browser windows\n\nThe comparison file is now open in Numbers. Would you like me to adjust any of the collected information or environment settings?",
    "extensions": [
      {
        "name": "Computer Controller",
        "command": "computercontroller",
        "is_builtin": true,
        "environmentVariables": []
      }
    ]
  },
  {
    "id": "youtube-to-blog",
    "title": "Convert YouTube Video to Blog Post",
    "description": "Generate a blog post from a YouTube video transcript",
    "category": "productivity",
    "job": "marketing-content",
    "featured": true,
    "example_prompt": "Get the transcript from this youtube video [link to video]. Then, summarize it into a blog post.",
    "example_result": "I've retrieved the transcript from the YouTube video about machine learning deployment best practices and created a blog post summary:\n\nTitle: Machine Learning in Production: Essential Best Practices for Deployment\n\nDeploying machine learning models to production environments requires careful planning and execution. In this comprehensive guide, we'll explore key best practices that ensure successful ML deployments.\n\nModel Versioning and Documentation\n- Implement semantic versioning for models (major.minor.patch)\n- Document all model assumptions and limitations\n- Track training data versions and preprocessing steps\n\nMonitoring and Observability\n- Set up comprehensive model performance metrics\n- Monitor prediction latency and resource usage\n- Implement data drift detection\n- Create alerting systems for critical metrics\n\nScalability Considerations\n- Design for horizontal scaling\n- Implement efficient batch prediction capabilities\n- Consider hardware requirements and costs\n- Use container orchestration for deployment\n\nTesting and Validation\n- Create comprehensive test suites for model behavior\n- Validate inputs and outputs thoroughly\n- Perform A/B testing before full deployment\n- Test system behavior under load\n\nConclusion:\nSuccessful ML deployment requires a systematic approach to versioning, monitoring, scaling, and testing. By following these best practices, teams can ensure their models perform reliably in production environments.\n\nWould you like me to expand on any specific aspect of the blog post?",
    "extensions": [
      {
        "name": "YouTube Transcript",
        "command": "uvx --from git+https://github.com/jkawamoto/mcp-youtube-transcript mcp-youtube-transcript",
        "is_builtin": false,
        "environmentVariables": []
      }
    ]
  }
]
