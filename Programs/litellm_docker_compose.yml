version: "3.9"
services:
  litellm:
    image: ghcr.io/berriai/litellm:main-latest
    container_name: litellm
    volumes:
      - ./litellm_proxy_server_config.yaml:/app/proxy_server_config.yaml # mount your litellm config.yaml
    ports:
      - "4000:4000"
    env_file:
      - $HOME/.env
